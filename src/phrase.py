import json
import os
import random
from collections import defaultdict
import re
from shutil import copy
from typing import Dict, List, Literal, Set, Tuple

import requests
import spacy

from src.config_loader import config
from src.dialogue_generation import anthropic_generate, extract_json_from_llm_response
from src.nlp import (
    extract_spacy_lowercase_words,
    extract_substring_matches,
    extract_vocab_and_pos,
    get_verb_and_vocab_lists,
    remove_matching_words,
)


def generate_phrases_from_vocab_dict(
    vocab_dict: Dict[str, List[str]],
    max_iterations: int = 10,
    length_phrase: str = "6-9 words long",
    verbs_per_phrase: str = "one or two verbs",
    num_phrases: int = 100,
) -> List[str]:
    """This takes a dict with keys 'verbs' and 'vocab'  and constructs phrases using them, iterating through until all words are exhausted.
    Desgined for Longman Communication vocab lists with a verb : vocab ratio of about 1:4 and 1000 words tends to generate around 850 phrases in
    a range of tenses. A list of english phrases are returned."""

    verb_list_set = set(vocab_dict["verbs"])
    vocab_list_set = set(vocab_dict["vocab"])

    LONGMAN_PHRASES = []
    all_verbs_used = set()
    iteration_count = 0

    while (len(vocab_list_set) >= 5) and iteration_count < max_iterations:
        iteration_count += 1

        if len(vocab_list_set) < 150:
            # Switch to minimal phrase generation and use any verbs
            response = generate_minimal_phrases_with_llm(
                list(vocab_list_set),
                length_phrase=length_phrase,
                verbs_per_phrase=verbs_per_phrase,
            )
            new_phrases = extract_json_from_llm_response(response)["phrases"]
            vocab_used = extract_vocab_and_pos(new_phrases)
            words_used = get_verb_and_vocab_lists(vocab_used)

            verb_list_set = remove_matching_words(words_used["verbs"], verb_list_set)
            vocab_list_set = remove_matching_words(words_used["vocab"], vocab_list_set)

            # match on text as well
            all_lowercase_words = extract_spacy_lowercase_words(new_phrases)
            verb_list_set = remove_matching_words(all_lowercase_words, verb_list_set)
            vocab_list_set = remove_matching_words(all_lowercase_words, vocab_list_set)

            # match on substring - to account for 'words' in the longman dictionary that are > 1 words like 'aware of'
            substring_matches = extract_substring_matches(new_phrases, vocab_list_set)
            vocab_list_set = remove_matching_words(substring_matches, vocab_list_set)

            LONGMAN_PHRASES.extend(new_phrases)

            print(f"Iteration {iteration_count}/{max_iterations}")
            print(f"Generated {len(new_phrases)} phrases - with minimal phrase prompt")
            print(
                f"We have {len(verb_list_set)} verbs and {len(vocab_list_set)} vocab words left"
            )
            continue
        else:
            if len(verb_list_set) < 10:
                num_phrases = min(len(vocab_list_set), 100)  # Focus on exhausting vocab
                verb_list_set.update(all_verbs_used)  # Reintroduce all used verbs
            elif len(verb_list_set) < 50 and len(vocab_list_set) > 100:
                num_phrases = min(
                    len(verb_list_set) * 2, 100
                )  # Ensure we use all verbs
            else:
                num_phrases = 100

        verb_sample_size = min(75, len(verb_list_set))
        vocab_sample_size = min(75 * 3, len(vocab_list_set))

        verb_list_for_prompt = random.sample(list(verb_list_set), k=verb_sample_size)
        vocab_list_for_prompt = random.sample(list(vocab_list_set), k=vocab_sample_size)

        response = generate_phrases_with_llm(
            verb_list=verb_list_for_prompt,
            vocab_list=vocab_list_for_prompt,
            num_phrases=num_phrases,
            length_phrase=length_phrase,
            verbs_per_phrase=verbs_per_phrase,
        )

        new_phrases = extract_json_from_llm_response(response)["phrases"]
        LONGMAN_PHRASES.extend(new_phrases)

        # we now pull out the POS and words used in the phrases we just generated and split them back into
        # a dictionary with keys 'verbs' and 'vocab'
        vocab_pos_used = extract_vocab_and_pos(new_phrases)
        words_used = get_verb_and_vocab_lists(vocab_pos_used)

        verb_list_set = remove_matching_words(words_used["verbs"], verb_list_set)
        vocab_list_set = remove_matching_words(words_used["vocab"], vocab_list_set)

        # match on exact word text as well as sometimes the word in the longman dictionary is not a 'lemma' as generated by spacy
        all_lowercase_words = extract_spacy_lowercase_words(new_phrases)
        vocab_list_set = remove_matching_words(all_lowercase_words, vocab_list_set)

        all_verbs_used.update(words_used["verbs"])

        print(f"Iteration {iteration_count}/{max_iterations}")
        print(f"Generated {len(new_phrases)} phrases")
        print(
            f"We have {len(verb_list_set)} verbs and {len(vocab_list_set)} vocab words left"
        )

    if iteration_count == max_iterations:
        print(
            f"Reached maximum number of iterations ({max_iterations}). Stopping phrase generation."
        )
    else:
        print("All words have been used. Phrase generation complete.")

    return LONGMAN_PHRASES


def generate_phrases_with_llm(
    verb_list: List[str],
    vocab_list: List[str],
    num_phrases: int = 100,
    length_phrase: str = "6-9 words long",
    verbs_per_phrase: str = "one or two verbs",
) -> List[str]:
    prompt = f"""
    Task: Generate {num_phrases} unique English phrases using words from the provided verb and vocabulary lists. Each phrase should be {length_phrase} and use {verbs_per_phrase} (no more) per phrase.

    Verb List: {', '.join(verb_list)}
    Vocabulary List: {', '.join(vocab_list)}

    Requirements:
    1. Use only words from the provided lists, common articles (a, an, the), basic prepositions, and common pronouns (I, we, you, they, etc.).
    2. Each phrase must contain {verbs_per_phrase} from the verb list, and be {length_phrase}.
    3. Vary the verb tenses (present, past, future) across the phrases. Stick mainly to first and second person.
    4. Vary the type of phrase:
        - Imperative ("Don't be late...")
        - Simple statements ("The traffic was terrible...")
        - First-person expressions ("I enjoy...")
        - Question ("Shall we...?", "Do you ...?", "Did they...?")
    5. Make phrases active rather than passive, something you would commonly say rather than read.
    6. Ensure each output is a complete sentence or phrase (so you may extend the length if needed)
    7. Try to use all the words provided to create the {num_phrases} phrases.
    8. Make the phrases memorable by creating interesting or slightly humorous scenarios.

    Please return your response in the following JSON format:
    {{
        "phrases": [
            "Phrase 1",
            "Phrase 2",
            ...
        ]
    }}
    """

    # Here you would call your LLM with the prompt
    llm_response = anthropic_generate(prompt, max_tokens=5000)
    return llm_response


def generate_minimal_phrases_with_llm(
    word_list: List[str],
    length_phrase: str = "6-9 words long",
    verbs_per_phrase: str = "one or two verbs",
) -> List[str]:
    prompt = f"""
    Task: Create the minimum number of English phrases necessary to use all the words from the provided list at least once. Each phrase should be {length_phrase}.

    Word List: {', '.join(word_list)}

    Requirements:
    1. Use all words from the provided list at least once across all phrases.
    2. Create the minimum number of phrases possible while meeting requirement 1.
    3. Each phrase must contain {verbs_per_phrase} from the verb list, and be {length_phrase}.
    3a. Ensure each output is a complete sentence or phrase (so you may extend the length if needed)
    4. You may use additional common words (articles, prepositions, pronouns, basic verbs) that a beginner language learner would know to complete phrases.
    5. Prioritize exhausting the provided word list over creating a large number of phrases.
    6. Vary the verb tenses (present, past, future) across the phrases. Stick mainly to first and second person.
    7. Vary the type of phrase:
        - Imperative ("Don't be late...")
        - Simple statements ("The traffic was terrible...")
        - First-person expressions ("I enjoy...")
        - Question ("Shall we...?", "Do you ...?", "Did they...?")
    8. Make phrases active rather than passive, something you would commonly say rather than read.
    9. Make the phrases memorable by creating interesting or slightly humorous scenarios when possible.

    Please return your response in the following JSON format:
    {{
        "phrases": [
            "Phrase 1",
            "Phrase 2",
            ...
        ]
    }}
    """

    # Here you would call your LLM with the prompt
    llm_response = anthropic_generate(prompt, max_tokens=5000)
    return llm_response


def update_word_usage(data: List[Dict], used_words: List[str]) -> List[Dict]:
    for entry in data:
        if entry["word"] in used_words:
            entry["used"] = True
    return data


def get_text_from_dialogue(dialogue: List[Dict[str, str]]) -> List[str]:
    """ignoring the speaker, just gets all the utterances from a dialogue and puts
    them in a single list"""

    phrases = []
    for utterance in dialogue:
        phrases.append(utterance["text"])
    return phrases


def get_sentences_from_text(phrases: List[str]) -> List[str]:
    """Splits up phrases which might have more than one sentence per phrase and splits into a list of separate sentences.
    Returns a list of sentences.
    """

    nlp = spacy.load("en_core_web_md")
    sentences = []

    for phrase in phrases:
        doc = nlp(phrase)
        for sent in doc.sents:
            sentences.append(sent.text)
    return sentences


def generate_practice_phrases_from_dialogue(
    dialogue: List[Dict[str, str]]
) -> List[str]:
    """Uses an LLM call to create practice phrases from a longer dialogue"""
    phrases = get_text_from_dialogue(dialogue)

    llm_prompt = f"""
    I will provide you with a list of dialogue phrases. Your task is to create 20-30 new phrases based on this dialogue, this is to support language learning
     where we learn new ways of rearranging the vocabulary to create a wider range of phrases.
    To help yourself, first list the verbs, tenses and other vocab within the phrases this will help you adhere to the following rules:
    1. Use only the vocabulary, verbs, grammatical structures, and tenses present in the original dialogue.
    2. Ensure every verb and noun is used in a short phrase (2 - 4 words).
    3. Do not introduce any new words, tenses, or grammatical concepts not present in the original.
    4. You can change pronouns for more practice with verbs (e.g. 'they are' to 'I am' etc), rearrange words, and create shorter or simplified versions of the original phrases.
    5. Start with simple, short phrases (2-4 words) and gradually move to more complex ones (5-8 words). If the original dialogue has very long sentences then increase the length of the complex examples you give to match.
    6. Ensure that each new phrase is grammatically correct and makes sense on its own.
    7. Do not use any direct quotes from the original dialogue (as we will practice this later).
    7. Be creative in mixing elements from different parts of the dialogue.

    Here's a short example to illustrate the task:

    Original dialogue: 
    ["I love eating an apple every day.", "Apples are healthy and delicious."]

    Example output:
    {{
    "new_phrases": [
        "We love",
        "They love eating",
        "You love every day",
        "It's delicious",
        "We eat every day",
        "You're healthy",
        "You love apples",
        "A delicious apple",
        "Eating is healthy",
        "We love delicious apples",
        "You eat healthy apples every day",
        "They're delicious and healthy"
    ]
    }}

    Now, here's the dialogue for you to work with:
    {phrases}

    Please include in your output a JSON object with a single key "new_phrases" whose value is an array of the new phrases. 
    """

    llm_response = anthropic_generate(llm_prompt)
    new_phrases = extract_json_from_llm_response(llm_response)["new_phrases"]

    # now add the original sentences onto those
    original_sentences = get_sentences_from_text(phrases)

    return new_phrases + original_sentences
