{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file has been modified. Reloading...\n"
     ]
    }
   ],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "French\n",
      "fr-FR-Neural2-G fr-FR-Chirp3-HD-Zephyr fr-FR-Chirp3-HD-Puck\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "from src.config_loader import config\n",
    "print(config.TARGET_LANGUAGE_NAME)\n",
    "english_voice, female_voice, male_voice = config.get_voice_models()\n",
    "english_voice_story, female_voice_story, male_voice_story = config.get_voice_models(\"stories\")\n",
    "COLLECTION = \"WarmUp150\"\n",
    "print(female_voice.voice_id, female_voice_story.voice_id, male_voice_story.voice_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want a dictionary where the key is the hash of the phrase via clean_filename -> to make an efficient lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import (generate_and_upload_fast_audio,\n",
    "                                  generate_dialogue_audio_and_upload,\n",
    "                                  upload_phrases_audio_to_gcs)\n",
    "from src.chat import create_html_challenges, get_html_challenge_inputs\n",
    "from src.convert import clean_filename\n",
    "from src.dialogue_generation import translate_and_upload_dialogue\n",
    "from src.gcs_storage import (check_blob_exists, get_stories_from_collection,\n",
    "                             get_story_challenges_path,\n",
    "                             get_story_collection_path,\n",
    "                             get_story_dialogue_path,\n",
    "                             get_story_translated_dialogue_path,\n",
    "                             get_translated_phrases_path,\n",
    "                             get_wiktionary_cache_path, read_from_gcs,\n",
    "                             upload_to_gcs)\n",
    "from src.story import (create_album_files, create_and_upload_html_story,\n",
    "                       prepare_dialogue_with_wiktionary,\n",
    "                       prepare_story_data_from_gcs)\n",
    "from src.translation import (review_story_dialogue_translations,\n",
    "                             review_translated_phrases_batch,\n",
    "                             translate_phrases)\n",
    "from src.wiktionary import add_wiktionary_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_stories = get_stories_from_collection(collection=COLLECTION)\n",
    "\n",
    "story_collection = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET,\n",
    "file_path = get_story_collection_path(collection=COLLECTION))\n",
    "translated_phrases_path = get_translated_phrases_path(collection=COLLECTION)\n",
    "\n",
    "language_name_lower = config.TARGET_LANGUAGE_NAME.lower()\n",
    "\n",
    "# google translate\n",
    "results = dict()\n",
    "for story in all_stories:\n",
    "    # Extract just the phrases from the story's phrase list\n",
    "    english_phrases = [item['phrase'] for item in story_collection[story]]\n",
    "    translated_phrases = translate_phrases(english_phrases)\n",
    "    for phrase, translation in translated_phrases:\n",
    "        phrase_key = clean_filename(phrase)\n",
    "        results[phrase_key] = {\"english\": phrase,\n",
    "                             language_name_lower: translation}\n",
    "        \n",
    "# refine translations\n",
    "upload_to_gcs(results, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=translated_phrases_path)\n",
    "phrase_translations = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET, file_path=translated_phrases_path)\n",
    "improved_translations = review_translated_phrases_batch(phrase_translations, model = \"claude-3-5-sonnet-latest\")\n",
    "upload_to_gcs(obj=improved_translations, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=translated_phrases_path)\n",
    "\n",
    "#wiktionary\n",
    "word_link_cache= read_from_gcs(config.GCS_PRIVATE_BUCKET, file_path = get_wiktionary_cache_path())\n",
    "phrase_translations, word_link_cache = add_wiktionary_links(improved_translations, word_link_cache, overwrite=False)\n",
    "upload_to_gcs(obj=phrase_translations, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=get_translated_phrases_path(collection=COLLECTION))\n",
    "upload_to_gcs(word_link_cache, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=get_wiktionary_cache_path())\n",
    "\n",
    "#process audio\n",
    "result = upload_phrases_audio_to_gcs(phrase_translations, overwrite=False)\n",
    "\n",
    "# translate stories\n",
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    story_file_path = get_story_dialogue_path(story_name, collection=COLLECTION)\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=COLLECTION)\n",
    "    if check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} already translated\")\n",
    "        #continue\n",
    "    story_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, story_file_path)\n",
    "    translate_and_upload_dialogue(story_dialogue, story_name, collection=COLLECTION)\n",
    "\n",
    "# refine translations\n",
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=COLLECTION)\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    reviewed_dialogue = review_story_dialogue_translations(translated_dialogue)\n",
    "    upload_to_gcs(obj=reviewed_dialogue, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=translated_file_path)\n",
    "\n",
    "# add wiktionary links\n",
    "for story_name in all_stories:\n",
    "\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=COLLECTION)\n",
    "    if not check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} not yet translated\")\n",
    "        continue\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    translated_dialogue_with_links = prepare_dialogue_with_wiktionary(translated_dialogue)\n",
    "    # now re-upload it with embedded witkionary_links\n",
    "    upload_to_gcs(obj=translated_dialogue_with_links, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=translated_file_path)\n",
    "\n",
    "# add audio\n",
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=COLLECTION)\n",
    "\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    generate_dialogue_audio_and_upload(translated_dialogue, story_name, collection=COLLECTION, overwrite=True)\n",
    "\n",
    "# add fast audio\n",
    "for story_name in tqdm(all_stories):\n",
    "    # uploads 1 fast mp3 file for each story part. \n",
    "    generate_and_upload_fast_audio(story_name, collection=COLLECTION, overwrite=True)\n",
    "\n",
    "# challenges\n",
    "\n",
    "for story_name in all_stories:\n",
    "    challenge_file_path = get_story_challenges_path(story_name, collection=COLLECTION)\n",
    "    scenario_dicts = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET, file_path=challenge_file_path)\n",
    "    challenges = get_html_challenge_inputs(scenario_dicts)\n",
    "    chat_webpage_file = create_html_challenges(challenges, story_name=story_name, collection=COLLECTION) # this creates and uploades\n",
    "\n",
    "# create stories\n",
    "for story_name in all_stories:\n",
    "    print(story_name)\n",
    "    story_data = prepare_story_data_from_gcs(story_name, collection=COLLECTION)\n",
    "    create_and_upload_html_story(story_data, story_name, collection=COLLECTION)\n",
    "    create_album_files(story_data, story_name, collection=COLLECTION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get a translation from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.story import update_all_index_pages_hierarchical, upload_styles_to_gcs\n",
    "upload_styles_to_gcs()\n",
    "update_all_index_pages_hierarchical(languages=[\"French\", \"Spanish\", \"German\", \"Swedish\"], collections=[\"LM1000\", \"WarmUp150\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
