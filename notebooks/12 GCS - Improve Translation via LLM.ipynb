{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from src.utils import (load_json, get_first_n_items, save_json, save_text_file, load_text_file, clean_filename, read_from_gcs, upload_to_gcs)  # noqa: E402\n",
    "from src.config_loader import config\n",
    "from src.translation import review_translations_with_anthropic, process_translations_in_batches\n",
    "config.TARGET_LANGUAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Refinement\n",
    "\n",
    "## Issues with Google Translate\n",
    "\n",
    "It can sound stiff / formal and be more related to written text rather than verbal.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Use Sonnet 3.5 via the Anthropic API, using a tool to return adjusted translations in JSON format for re-uploading to our phrase translation store (json file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current translated JSON file\n",
    "\n",
    "phrase_translations = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET, file_path=f\"collections/LM1000/translations/{config.TARGET_LANGUAGE_NAME.lower()}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = get_first_n_items(phrase_translations, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_translations = process_translations_in_batches(test_dict, model = \"haiku-3-5-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the LM1000.json() file\n",
    "\n",
    "LM1000 = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET,\n",
    "file_path = \"collections/LM1000/LM1000-with-stories.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.TARGET_LANGUAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want a dictionary where the key is the hash of the phrase via clean_filename -> to make an efficient lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.translation import translate_phrases\n",
    "language_name_lower = config.TARGET_LANGUAGE_NAME.lower()\n",
    "\n",
    "results = dict()\n",
    "for story in LM1000:\n",
    "    # get all translations from a list\n",
    "    english_phrases = LM1000[story]\n",
    "    translated_phrases = translate_phrases(english_phrases)\n",
    "    for phrase, translation in translated_phrases:\n",
    "        phrase_key = clean_filename(phrase)\n",
    "        results[phrase_key] = {\"english\" : phrase,\n",
    "                                language_name_lower : translation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_gcs(results, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=f\"collections/LM1000/translations/{language_name_lower}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get a translation from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_lookup = results\n",
    "\n",
    "example_phrase = LM1000['story_a_fishing_trip'][5]\n",
    "\n",
    "translation_lookup[clean_filename(example_phrase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
