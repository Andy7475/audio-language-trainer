{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from setup_imports import *  # noqa: F401,F403\n",
    "from src.phrases.phrase_model import Phrase, Translation, get_phrase, get_phrase_by_english\n",
    "from src.models import BCP47Language\n",
    "from src.connections.gcloud_auth import get_firestore_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40235f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new phrase\n",
    "phrase = Phrase.create_phrase(\"She runs to the store daily\", source=\"manual\")\n",
    "print(f\"Created phrase: {phrase.english}\")\n",
    "print(f\"Phrase hash: {phrase.phrase_hash}\")\n",
    "print(f\"Phrase model dump:\\n{phrase.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd74f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Translate the phrase to French\n",
    "fr_translation = phrase.translate(BCP47Language.get(\"fr-FR\"), refine=False)\n",
    "print(f\"French translation: {fr_translation.text}\")\n",
    "print(f\"Language: {fr_translation.language.to_tag()}\")\n",
    "print(f\"Tokens: {fr_translation.tokens}\")\n",
    "print(f\"Audio: {fr_translation.audio}\")  # Should be None initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf76060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Add another translation (German) and verify translations list\n",
    "de_translation = phrase.translate(BCP47Language.get(\"de-DE\"), refine=False)\n",
    "print(f\"German translation: {de_translation.text}\")\n",
    "print(f\"\\nTotal translations on phrase: {len(phrase.translations)}\")\n",
    "for trans in phrase.translations:\n",
    "    print(f\"  - {trans.language.to_tag()}: {trans.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Upload phrase to Firestore\n",
    "firestore_client = get_firestore_client(\"firephrases\")\n",
    "uploaded_hash = phrase.upload_phrase(firestore_client)\n",
    "print(f\"Uploaded phrase with hash: {uploaded_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed131bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Retrieve phrase by hash\n",
    "retrieved_phrase = get_phrase(uploaded_hash)\n",
    "print(f\"Retrieved phrase: {retrieved_phrase.english}\")\n",
    "print(f\"Phrase hash: {retrieved_phrase.phrase_hash}\")\n",
    "print(f\"Source: {retrieved_phrase.source}\")\n",
    "print(f\"Translations: {len(retrieved_phrase.translations)}\")\n",
    "for trans in retrieved_phrase.translations:\n",
    "    print(f\"  - {trans.language.to_tag()}: {trans.text}\")\n",
    "print(f\"\\nRetrieved phrase model_dump:\\n{retrieved_phrase.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fcae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Retrieve phrase by English text (convenience wrapper)\n",
    "english_phrase = \"She runs to the store daily\"\n",
    "retrieved_by_english = get_phrase_by_english(english_phrase)\n",
    "print(f\"Retrieved by English text: {retrieved_by_english.english}\")\n",
    "print(f\"Hash: {retrieved_by_english.phrase_hash}\")\n",
    "print(f\"Translations: {len(retrieved_by_english.translations)}\")\n",
    "for trans in retrieved_by_english.translations:\n",
    "    print(f\"  - {trans.language.to_tag()}: {trans.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab998641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Verify data integrity - compare original and retrieved\n",
    "print(\"=== Data Integrity Check ===\")\n",
    "print(f\"English matches: {phrase.english == retrieved_phrase.english}\")\n",
    "print(f\"Hash matches: {phrase.phrase_hash == retrieved_phrase.phrase_hash}\")\n",
    "print(f\"Translation count matches: {len(phrase.translations) == len(retrieved_phrase.translations)}\")\n",
    "\n",
    "# Verify each translation\n",
    "original_translations = {t.language.to_tag(): t.text for t in phrase.translations}\n",
    "retrieved_translations = {t.language.to_tag(): t.text for t in retrieved_phrase.translations}\n",
    "\n",
    "print(f\"\\nOriginal translations: {original_translations}\")\n",
    "print(f\"Retrieved translations: {retrieved_translations}\")\n",
    "print(f\"Translations match: {original_translations == retrieved_translations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5nuywu3iswi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Audio module imported successfully\n",
      "✓ Supported languages: fr-FR, ru-RU, it-IT, nb-NO, sv-SE, cmn-CN, en-GB, es-ES, de-DE, cy-GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AUDIO MODULE EXAMPLES\n",
    "# ============================================================\n",
    "# The new audio module provides TTS, audio processing, and voice management\n",
    "# Features:\n",
    "# - Multiple TTS providers (Google, Azure, ElevenLabs)\n",
    "# - Slow speech with word breaks for learning\n",
    "# - Local fast audio processing (no API calls)\n",
    "# - Parameter-driven API (no global config)\n",
    "\n",
    "from src.audio import (\n",
    "    load_voices_from_json,\n",
    "    get_voice_model,\n",
    "    get_voice_models,\n",
    "    generate_translation_audio,\n",
    "    generate_fast_audio,\n",
    "    generate_normal_and_fast_audio,\n",
    "    join_audio_segments,\n",
    "    export_audio,\n",
    ")\n",
    "\n",
    "print(\"✓ Audio module imported successfully\")\n",
    "print(f\"✓ Supported languages: {', '.join(load_voices_from_json().keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mfw73zdxhyc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27993811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoiceInfo(provider=<VoiceProvider.GOOGLE: 'google'>, voice_id='fr-FR-Neural2-G', language_code='fr-FR')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0hcekeevebh9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Generating audio for French phrase\n",
      "Text: 'Bonjour, comment allez-vous?'\n",
      "Voice: google - fr-FR-Neural2-G\n",
      "\n",
      "To generate audio, you would call:\n",
      "\n",
      "# Normal speed audio\n",
      "normal_audio = generate_translation_audio(\n",
      "    translated_text=\"Bonjour, comment allez-vous?\",\n",
      "    voice_model=fr_voice,\n",
      "    speed='normal'\n",
      ")\n",
      "\n",
      "# Slow speech with word breaks (for learning)\n",
      "slow_audio = generate_translation_audio(\n",
      "    translated_text=\"Bonjour, comment allez-vous?\",\n",
      "    voice_model=fr_voice,\n",
      "    speed='slow'\n",
      ")\n",
      "\n",
      "# Custom word break timing (in milliseconds)\n",
      "slow_audio = generate_translation_audio(\n",
      "    translated_text=\"Bonjour, comment allez-vous?\",\n",
      "    voice_model=fr_voice,\n",
      "    speed='slow',\n",
      "    word_break_ms=500  # 500ms between words\n",
      ")\n",
      "\n",
      "✓ Note: Audio generation requires API credentials:\n",
      "  - Google Cloud TTS: GOOGLE_APPLICATION_CREDENTIALS env var\n",
      "  - Azure: AZURE_API_KEY and AZURE_REGION env vars\n",
      "  - ElevenLabs: ELEVENLABS_API_KEY env var\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate audio for a translation at different speeds\n",
    "# (These won't actually generate audio without proper API credentials,\n",
    "#  but show how to structure the calls)\n",
    "\n",
    "test_text = \"Bonjour, comment allez-vous?\"\n",
    "fr_voice = get_voice_model(\"fr-FR\", \"FEMALE\", \"flashcards\")\n",
    "\n",
    "print(f\"Example: Generating audio for French phrase\")\n",
    "print(f\"Text: '{test_text}'\")\n",
    "print(f\"Voice: {fr_voice.provider.value} - {fr_voice.voice_id}\")\n",
    "print(f\"\\nTo generate audio, you would call:\")\n",
    "print()\n",
    "print(\"# Normal speed audio\")\n",
    "print(\"normal_audio = generate_translation_audio(\")\n",
    "print(f\"    translated_text=\\\"{test_text}\\\",\")\n",
    "print(f\"    voice_model=fr_voice,\")\n",
    "print(f\"    speed='normal'\")\n",
    "print(\")\")\n",
    "print()\n",
    "print(\"# Slow speech with word breaks (for learning)\")\n",
    "print(\"slow_audio = generate_translation_audio(\")\n",
    "print(f\"    translated_text=\\\"{test_text}\\\",\")\n",
    "print(f\"    voice_model=fr_voice,\")\n",
    "print(f\"    speed='slow'\")\n",
    "print(\")\")\n",
    "print()\n",
    "print(\"# Custom word break timing (in milliseconds)\")\n",
    "print(\"slow_audio = generate_translation_audio(\")\n",
    "print(f\"    translated_text=\\\"{test_text}\\\",\")\n",
    "print(f\"    voice_model=fr_voice,\")\n",
    "print(f\"    speed='slow',\")\n",
    "print(f\"    word_break_ms=500  # 500ms between words\")\n",
    "print(\")\")\n",
    "print()\n",
    "print(\"✓ Note: Audio generation requires API credentials:\")\n",
    "print(\"  - Google Cloud TTS: GOOGLE_APPLICATION_CREDENTIALS env var\")\n",
    "print(\"  - Azure: AZURE_API_KEY and AZURE_REGION env vars\")\n",
    "print(\"  - ElevenLabs: ELEVENLABS_API_KEY env var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "va7pncdr4dr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Audio processing (can work without API credentials - uses dummy audio)\n",
    "from pydub import AudioSegment\n",
    "\n",
    "print(\"=== Audio Processing Examples ===\\n\")\n",
    "\n",
    "# Create some dummy silent audio segments (in practice, these would be TTS outputs)\n",
    "segment1 = AudioSegment.silent(duration=500)   # 500ms silent audio\n",
    "segment2 = AudioSegment.silent(duration=500)   # 500ms silent audio\n",
    "segment3 = AudioSegment.silent(duration=500)   # 500ms silent audio\n",
    "\n",
    "print(f\"Created 3 audio segments of 500ms each\")\n",
    "\n",
    "# Join audio segments with a gap\n",
    "joined = join_audio_segments([segment1, segment2, segment3], gap_ms=100)\n",
    "print(f\"\\n✓ Joined segments with 100ms gaps\")\n",
    "print(f\"  Total duration: {len(joined)}ms (500 + 100 + 500 + 100 + 500 = 1700ms)\")\n",
    "\n",
    "# Export to file\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    output_file = Path(tmpdir) / \"test_audio.mp3\"\n",
    "    export_audio(joined, filename=str(output_file))\n",
    "    print(f\"\\n✓ Exported audio to: {output_file.name}\")\n",
    "    print(f\"  File exists: {output_file.exists()}\")\n",
    "    print(f\"  File size: {output_file.stat().st_size} bytes\")\n",
    "\n",
    "print(\"\\n✓ Audio processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bew16j5r2nf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Integration example - using audio with phrases\n",
    "print(\"=== Integration: Phrase + Audio Workflow ===\\n\")\n",
    "\n",
    "# Recall our phrase and translations from earlier\n",
    "print(f\"Phrase: '{phrase.english}'\")\n",
    "print(f\"Has {len(phrase.translations)} translations:\")\n",
    "for trans in phrase.translations:\n",
    "    lang_tag = trans.language.to_tag()\n",
    "    print(f\"  - {lang_tag}: {trans.text}\")\n",
    "\n",
    "print(\"\\n✓ To generate audio for each translation:\")\n",
    "print()\n",
    "\n",
    "# Show the workflow for each translation\n",
    "for trans in phrase.translations:\n",
    "    lang_tag = trans.language.to_tag()\n",
    "    lang_code = lang_tag  # e.g., \"fr-FR\", \"de-DE\"\n",
    "    \n",
    "    # Get voice for this language (using female voice for flashcards)\n",
    "    try:\n",
    "        voice = get_voice_model(lang_code, \"FEMALE\", \"flashcards\")\n",
    "        print(f\"{lang_tag}: {voice.provider.value}\")\n",
    "        print(f\"  # Generate audio\")\n",
    "        print(f\"  normal_audio = generate_translation_audio(\")\n",
    "        print(f\"      translated_text=\\\"{trans.text}\\\",\")\n",
    "        print(f\"      voice_model=voice,\")\n",
    "        print(f\"      speed='normal'\")\n",
    "        print(f\"  )\")\n",
    "        print(f\"  slow_audio = generate_translation_audio(\")\n",
    "        print(f\"      translated_text=\\\"{trans.text}\\\",\")\n",
    "        print(f\"      voice_model=voice,\")\n",
    "        print(f\"      speed='slow'\")\n",
    "        print(f\"  )\")\n",
    "        print()\n",
    "    except ValueError as e:\n",
    "        print(f\"{lang_tag}: Not configured - {e}\")\n",
    "\n",
    "print(\"✓ This workflow would generate:\")\n",
    "print(\"  - Normal speed audio for natural listening\")\n",
    "print(\"  - Slow speed audio with word breaks for learning\")\n",
    "print(\"  - All audio linked to the translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pnp771uyfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Audio Module Constants ===\n",
      "\n",
      "Speaking Rates:\n",
      "  SPEAKING_RATE_NORMAL: 1.0x (natural speed)\n",
      "  SPEAKING_RATE_SLOW:   0.85x (slower for learning)\n",
      "\n",
      "Audio Processing:\n",
      "  AUDIO_SPEED_NORMAL: 1.0x\n",
      "  AUDIO_SPEED_FAST:   2.0x (local processing, no API call)\n",
      "\n",
      "Timing:\n",
      "  DEFAULT_WORD_BREAK_MS: 250ms (break between words)\n",
      "  DEFAULT_GAP_MS:        100ms (gap between audio segments)\n",
      "\n",
      "Voice Providers:\n",
      "  - google\n",
      "  - azure\n",
      "  - elevenlabs\n",
      "\n",
      "✓ All audio features are now ready to use!\n",
      "  See AUDIO_MODULE_GUIDE.md for complete documentation\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Audio module constants and settings\n",
    "from src.audio import (\n",
    "    SPEAKING_RATE_SLOW,\n",
    "    SPEAKING_RATE_NORMAL,\n",
    "    AUDIO_SPEED_FAST,\n",
    "    AUDIO_SPEED_NORMAL,\n",
    "    DEFAULT_WORD_BREAK_MS,\n",
    "    DEFAULT_GAP_MS,\n",
    "    VoiceProvider,\n",
    ")\n",
    "\n",
    "print(\"=== Audio Module Constants ===\\n\")\n",
    "\n",
    "print(\"Speaking Rates:\")\n",
    "print(f\"  SPEAKING_RATE_NORMAL: {SPEAKING_RATE_NORMAL}x (natural speed)\")\n",
    "print(f\"  SPEAKING_RATE_SLOW:   {SPEAKING_RATE_SLOW}x (slower for learning)\")\n",
    "print()\n",
    "\n",
    "print(\"Audio Processing:\")\n",
    "print(f\"  AUDIO_SPEED_NORMAL: {AUDIO_SPEED_NORMAL}x\")\n",
    "print(f\"  AUDIO_SPEED_FAST:   {AUDIO_SPEED_FAST}x (local processing, no API call)\")\n",
    "print()\n",
    "\n",
    "print(\"Timing:\")\n",
    "print(f\"  DEFAULT_WORD_BREAK_MS: {DEFAULT_WORD_BREAK_MS}ms (break between words)\")\n",
    "print(f\"  DEFAULT_GAP_MS:        {DEFAULT_GAP_MS}ms (gap between audio segments)\")\n",
    "print()\n",
    "\n",
    "print(\"Voice Providers:\")\n",
    "for provider in VoiceProvider:\n",
    "    print(f\"  - {provider.value}\")\n",
    "print()\n",
    "\n",
    "print(\"✓ All audio features are now ready to use!\")\n",
    "print(\"  See AUDIO_MODULE_GUIDE.md for complete documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c264377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
