{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from setup_imports import *  # noqa: F401,F403\n",
    "\n",
    "from src.phrases.generation import generate_phrases_from_vocab_dict\n",
    "from src.utils import (\n",
    "    load_json,\n",
    "    save_text_file,\n",
    "    get_longman_verb_vocab_dict,\n",
    "    load_text_file,\n",
    ")\n",
    "from src.phrases.phrase_model import Phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Generation\n",
    "\n",
    "We will have short, simple verb phrases, and associated vocab-only phrases from a vocab_dict. The deliberate removal of verbs from vocab phrases is designed to make the cards easier, and split those tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = load_json(\"..\\data\\gcse_vocab_list_cambridge.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first2000 = get_longman_verb_vocab_dict(\n",
    "    \"..\\data\\longman-communication-3000.json\", category=\"S2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create then shuffle-up verbs and vocab\n",
    "\n",
    "# from random import shuffle\n",
    "\n",
    "\n",
    "# all_verbs = (first2000['verbs'])\n",
    "# all_vocab = (first2000['vocab'])\n",
    "# shuffle(all_verbs)\n",
    "# shuffle(all_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_text_file(all_verbs, \"../data/LM2000_verbs.txt\")\n",
    "# save_text_file(all_vocab, \"../data/LM2000_vocab.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_verbs = load_text_file(\"../data/LM2000_verbs.txt\")\n",
    "all_vocab = load_text_file(\"../data/LM2000_vocab.txt\")\n",
    "print(f\"num verbs: {len(all_verbs)}, num vocab: {len(all_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aim for 10 verbs and 50 vocab\n",
    "FROM_INDEX = 20\n",
    "TO_INDEX = FROM_INDEX + 10\n",
    "VOCAB_FROM_INDEX = int((FROM_INDEX / 10) * 50)\n",
    "VOCAB_TO_INDEX = VOCAB_FROM_INDEX + 50\n",
    "\n",
    "\n",
    "COLLECTION = \"LM2000\"\n",
    "DECK = \"Pack03\"\n",
    "some_verbs = all_verbs[FROM_INDEX:TO_INDEX]\n",
    "some_vocab = all_vocab[VOCAB_FROM_INDEX:VOCAB_TO_INDEX]\n",
    "\n",
    "current_dict = {}\n",
    "current_dict[\"verbs\"] = list(some_verbs)\n",
    "current_dict[\"vocab\"] = list(some_vocab)\n",
    "\n",
    "print(\n",
    "    f\"FROM_INDEX: {FROM_INDEX}, TO_INDEX: {TO_INDEX}, VOCAB_FROM_INDEX: {VOCAB_FROM_INDEX}, VOCAB_TO_INDEX: {VOCAB_TO_INDEX}, len verbs: {len(some_verbs)}, len vocab: {len(some_vocab)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_phrases = generate_phrases_from_vocab_dict(\n",
    "    current_dict,\n",
    "    max_iterations=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text_file(generated_phrases[0], f\"..\\data\\LM2000-{FROM_INDEX}-{TO_INDEX}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_phrases = load_text_file(f\"..\\data\\LM2000-{FROM_INDEX}-{TO_INDEX}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_phrases = load_text_file(Path(\"..\\data\\phrases\\\\biology_lesson_test.txt\"))\n",
    "COLLECTION = \"Biology\"\n",
    "DECK = \"Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_PHRASES = []\n",
    "for phrase in generated_phrases:\n",
    "    p = Phrase.create(phrase)\n",
    "    p.collection = COLLECTION\n",
    "    p.deck = DECK\n",
    "    p.generate_image()\n",
    "    #p.translate(\"uk-UA\", refine=True, overwrite=True)\n",
    "    p.generate_audio(context=\"flashcard\", language=\"en-GB\")\n",
    "    p.upload(overwrite=True)\n",
    "    ALL_PHRASES.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_PHRASES[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
