{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'French'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.utils import load_json, save_text_file, load_text_file\n",
    "from src.nlp import get_vocab_dictionary_from_phrases\n",
    "from src.utils import get_longman_verb_vocab_dict, save_text_file, load_text_file\n",
    "from src.phrase import generate_phrases_from_vocab_dict, generate_scenario_phrases, generate_scenario_vocab_building_phrases\n",
    "from src.config_loader import config\n",
    "from src.gcs_storage import get_phrase_index_path\n",
    "config.TARGET_LANGUAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Card Generation 01\n",
    "\n",
    "## Generate english phrases\n",
    "\n",
    "The core way we store vocabularly for generating phrases, and then flashcards, is in a dictionary with two keys. 'verbs' (for verbs in the infinitive form, like 'be', 'run') and 'vocab' (for everything else).\n",
    "\n",
    "The intent is that a vocab list is a core learning requirement (e.g. for an exam), and that it is easier to remember words in the context of common phrases. i.e. learning the phrase 'I want', and separtely learning the noun 'cake' is less efficient than learning the phrase 'I want some cake, please'.\n",
    "\n",
    "Even better if we link that phrase to an image and associated audio. This is the dual-encoding theory of langauge learning and leads to retention and recall benefits.\n",
    "\n",
    "The first step is generating your english phrases from your vocab list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longman corpus\n",
    "\n",
    "A common 'starter' corpus containing core words you should learn in terms of the 1st 1000 words, 2nd 1000 words etc\n",
    "\n",
    "You can replace vocab_dict with any custom made python dictionary with 'verbs' and 'vocab' keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gcs_storage import get_phrase_path, read_from_gcs, get_story_collection_path, upload_to_gcs\n",
    "\n",
    "story_collection = read_from_gcs(config.GCS_PRIVATE_BUCKET, get_story_collection_path(collection=\"LM1000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first 200 phrases\n",
    "all_phrases = []\n",
    "for story_name in story_collection:\n",
    "    all_phrases.extend([item['phrase'] for item in story_collection[story_name]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab_dict = get_vocab_dictionary_from_phrases(all_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_vocab_dict['verbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get warmUp vocab dict\n",
    "first200_vocab_dict = get_vocab_dictionary_from_phrases(all_phrases[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first200_vocab_dict['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = '../data/longman-communication-3000.json' # a specifc format\n",
    "vocab_dict = get_longman_verb_vocab_dict(file_path, \"S2\") #S1 = 1st 1000 words used in Speech, W2 = 2nd 1000 words used in written etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating conversational phrases from a vocabulary dictionary\n",
    "\n",
    "This function will iterate through (by sampling) the vocabularly dictionary, until it is exhausted.\n",
    "We run a check against generated phrases so we can 'tick off' words already used.\n",
    "\n",
    "Phrases are generated using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or for GCSE vocab:\n",
    "vocab_dict = load_json(\"..\\data\\gcse_vocab_list_cambridge.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/12 - Generating 100 phrases\n",
      "Function that called this one: generate_phrases_with_llm. Sleeping for 20 seconds\n",
      "Generated 99 phrases\n",
      "We have 78 verbs and 214 vocab words left\n",
      "Iteration 2/12 - Generating 100 phrases\n",
      "Function that called this one: generate_phrases_with_llm. Sleeping for 20 seconds\n",
      "Generated 101 phrases\n",
      "We have 6 verbs and 129 vocab words left\n",
      "Iteration 3/12 - Using minimal phrase generation\n",
      "Function that called this one: generate_minimal_phrases_with_llm. Sleeping for 20 seconds\n",
      "Generated 50 phrases - with minimal phrase prompt\n",
      "We have 1 verbs and 5 vocab words left\n",
      "Iteration 4/12 - Using minimal phrase generation\n",
      "Function that called this one: generate_minimal_phrases_with_llm. Sleeping for 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m██████████████\u001b[0m| 2/2 [00:02<00:00,  1.01s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 phrases - with minimal phrase prompt\n",
      "We have 0 verbs and 0 vocab words left\n",
      "All words have been used. Phrase generation complete. Generated 253 phrases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#comment out the below two lines to go for the default of 6 - 9 word phrases and no more than 2 verbs\n",
    "length_phrase = \"4-5 words long, for beginner GCSE level, but treat common lexical chunks (I'm going to.., Do you.., Let us.. etc) as a single 'word'\"\n",
    "verbs_per_phrase = \"one verb (but OK for an additional auxillary verb if necessary)\"\n",
    "localise = False # whether to tweak the prompt to set phrases within the target country\n",
    "generated_phrases = generate_phrases_from_vocab_dict(   \n",
    "    first200_vocab_dict, max_iterations=12,\n",
    "      length_phrase=length_phrase,\n",
    "        verbs_per_phrase=verbs_per_phrase,\n",
    "        localise=localise)\n",
    "#It takes about 15 iterations to go through 200 verbs, 800 vocab (1000 words total)\n",
    "#You will end up with about 1000 phrases, so get practice of the same verb etc in different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Let's eat lunch tomorrow\",\n",
       " 'Can you play the guitar?',\n",
       " 'I must finish my homework',\n",
       " \"Don't wake me up early\",\n",
       " 'Do you like my hat?',\n",
       " 'They arrived at the airport',\n",
       " \"I can't find my coat\",\n",
       " 'Shall we go shopping today?',\n",
       " 'The cake tastes delicious',\n",
       " 'Could you help me, please?',\n",
       " \"I'm going to the bank\",\n",
       " 'Did you see that film?',\n",
       " 'We need to leave now',\n",
       " \"Don't worry about the test\",\n",
       " 'Can I borrow your car?',\n",
       " \"Let's have a party tonight\",\n",
       " 'I love your new dress',\n",
       " 'Do you understand the question?',\n",
       " \"They're getting married next month\",\n",
       " \"I'm trying to lose weight\",\n",
       " \"Don't forget your umbrella today\",\n",
       " 'Can you call me later?',\n",
       " 'I hope you feel better',\n",
       " \"Let's meet at the church\",\n",
       " 'Do you believe in ghosts?',\n",
       " \"I can't stand the traffic\",\n",
       " 'We should grow more flowers',\n",
       " \"Don't break my heart, please\",\n",
       " 'Can you explain this concept?',\n",
       " 'I might go abroad soon',\n",
       " \"Let's watch a movie tonight\",\n",
       " 'Do you know the way?',\n",
       " \"I can't open this door\",\n",
       " 'We should try that restaurant',\n",
       " \"Don't lose your train ticket\",\n",
       " 'Can you carry this bag?',\n",
       " 'I love the spring weather',\n",
       " \"Let's plan our next trip\",\n",
       " 'Do you mind the noise?',\n",
       " \"I can't remember her name\",\n",
       " 'We should save some money',\n",
       " \"Don't fall asleep yet, please\",\n",
       " 'Can you change the channel?',\n",
       " 'I might buy a new car',\n",
       " \"Let's have dinner outside tonight\",\n",
       " 'Do you speak any languages?',\n",
       " \"I can't deal with this\",\n",
       " 'We should hang these pictures',\n",
       " \"Don't hurt yourself, be careful\",\n",
       " 'Can you share your notes?',\n",
       " 'I love your new haircut',\n",
       " \"Let's go to the park\",\n",
       " 'Do you like spicy food?',\n",
       " \"I can't stand this heat\",\n",
       " 'We should maintain our friendship',\n",
       " \"Don't bother him now, please\",\n",
       " 'Can you film the concert?',\n",
       " 'I might learn to drive',\n",
       " \"Let's have a picnic tomorrow\",\n",
       " 'Do you need any help?',\n",
       " \"I can't decide what to wear\",\n",
       " 'We should enhance our skills',\n",
       " \"Don't drop that glass, please\",\n",
       " 'Can you taste this soup?',\n",
       " 'I love this time of year',\n",
       " \"Let's go for a walk\",\n",
       " 'Do you care about politics?',\n",
       " \"I can't find my keys\",\n",
       " 'We should fight for our rights',\n",
       " \"Don't wake the baby, please\",\n",
       " 'Can you stick around longer?',\n",
       " 'I might get a new job',\n",
       " \"Let's celebrate your birthday soon\",\n",
       " 'Do you feel any better?',\n",
       " \"I can't understand this puzzle\",\n",
       " 'We should sell these old books',\n",
       " \"Don't miss the train, hurry!\",\n",
       " 'Can you choose a movie?',\n",
       " 'I love your new hairstyle',\n",
       " \"Let's have tea this afternoon\",\n",
       " 'Do you know that person?',\n",
       " \"I can't believe the news\",\n",
       " 'We should act more responsibly',\n",
       " \"Don't worry about the future\",\n",
       " 'Can you catch that bus?',\n",
       " 'I might go to bed early',\n",
       " \"Let's play a game tonight\",\n",
       " 'Do you have any plans?',\n",
       " \"I can't face him today\",\n",
       " 'We should change our routine',\n",
       " \"Don't forget your appointment, please\",\n",
       " 'Can you knock on the door?',\n",
       " 'I love this new song',\n",
       " \"Let's take a different route\",\n",
       " \"Do you think it'll rain?\",\n",
       " \"I can't work this weekend\",\n",
       " 'We should try something new',\n",
       " \"Don't lose hope, stay strong\",\n",
       " 'Can you speak more slowly?',\n",
       " \"Let's produce a documentary\",\n",
       " 'Can you resolve this issue?',\n",
       " 'Show me your passport',\n",
       " \"I'll apply for the job\",\n",
       " 'Shall we start the meeting?',\n",
       " 'Look at that beautiful sunset',\n",
       " 'Tell me about your holiday',\n",
       " \"I bet you're too busy\",\n",
       " 'How do you spend money?',\n",
       " 'Did you pay the bill?',\n",
       " \"I'll graduate from college soon\",\n",
       " \"Let's sit on the balcony\",\n",
       " 'What does that mean exactly?',\n",
       " 'We must defend our opinion',\n",
       " 'Can you organize the event?',\n",
       " 'Turn off the alarm please',\n",
       " 'I enjoy reading in bed',\n",
       " 'Put the plate in water',\n",
       " \"Let's dive into the adventure\",\n",
       " 'Who will teach the class?',\n",
       " 'Answer the phone quickly',\n",
       " 'Use this glove to cook',\n",
       " 'Do you want anything else?',\n",
       " 'Stop making such noise',\n",
       " \"I suppose you're right\",\n",
       " 'Can you lift this box?',\n",
       " \"Don't drag your feet\",\n",
       " \"Let's make a quick decision\",\n",
       " 'Did you win the lottery?',\n",
       " 'How long will it last?',\n",
       " 'Can we afford this holiday?',\n",
       " 'Shake hands with everyone',\n",
       " 'Get rid of old furniture',\n",
       " 'Would you like some tea?',\n",
       " \"They're building a new bridge\",\n",
       " 'Where do you live now?',\n",
       " 'I injured my hand badly',\n",
       " 'Will you accept this gift?',\n",
       " 'Does it really matter much?',\n",
       " 'Hold on to the rail',\n",
       " \"We'll bury the treasure here\",\n",
       " 'Imagine a world without fear',\n",
       " 'My goldfish died this morning',\n",
       " 'Does this coat fit you?',\n",
       " \"Let's prepare for the wedding\",\n",
       " 'Can you refer me to?',\n",
       " 'Consider the possible consequences',\n",
       " 'Did you notice anything odd?',\n",
       " 'Give me your honest opinion',\n",
       " 'Follow the road straight ahead',\n",
       " \"I can't figure it out\",\n",
       " 'Raise your hand to speak',\n",
       " 'May I offer you tea?',\n",
       " 'That sounds like a bell',\n",
       " 'How can we improve this?',\n",
       " \"Let's discuss the programme later\",\n",
       " 'Remind me to check in',\n",
       " \"I'll check the account balance\",\n",
       " 'Can we talk about this?',\n",
       " 'Note down the main points',\n",
       " 'What happened to your car?',\n",
       " 'I hate waking up early',\n",
       " 'Did you hear that noise?',\n",
       " \"Don't mention it to anyone\",\n",
       " \"Let's explore the reef tomorrow\",\n",
       " 'Please shut the door quietly',\n",
       " 'I enjoy cooking French food',\n",
       " 'Do you realize how late?',\n",
       " 'It seems like a mistake',\n",
       " 'Can you reach that shelf?',\n",
       " 'Cut the cake into half',\n",
       " 'What did you say again?',\n",
       " 'Ring me back later please',\n",
       " \"Let's head to the library\",\n",
       " 'I support your decision completely',\n",
       " 'Produce a solution by Friday',\n",
       " 'How will you resolve this?',\n",
       " 'Show me how it works',\n",
       " 'Apply the cream carefully please',\n",
       " 'When does the show start?',\n",
       " 'Look out for the driver',\n",
       " 'Tell us about your adventure',\n",
       " \"I bet it's too expensive\",\n",
       " 'How do you spend weekends?',\n",
       " 'Pay attention to the teacher',\n",
       " 'Did you graduate last year?',\n",
       " \"Let's sit in the garden\",\n",
       " 'What do you mean exactly?',\n",
       " 'We must defend our culture',\n",
       " 'Can you organize my wedding?',\n",
       " 'Turn down the TV volume',\n",
       " 'I enjoy reading good books',\n",
       " 'Put some air in tyres',\n",
       " \"Let's dive into the project\",\n",
       " 'Who will teach us golf?',\n",
       " 'Answer the door please',\n",
       " 'Use this map to navigate',\n",
       " 'Do you want to shop?',\n",
       " 'Stop worrying about everything',\n",
       " \"I suppose it's possible\",\n",
       " 'Can you lift this safely?',\n",
       " 'Do you have a great idea?',\n",
       " \"I'm going to school calmly\",\n",
       " 'Speak softly against the danger',\n",
       " \"Let's get a free loan\",\n",
       " 'Are you ready for local concern?',\n",
       " 'The first fifty pounds definitely',\n",
       " 'Truth is an interesting possibility',\n",
       " 'Bring the stove before night',\n",
       " 'Every regional product is fine',\n",
       " 'His big office has options',\n",
       " 'Many soldiers died that hour',\n",
       " 'The original team is speaking',\n",
       " 'If someone lives forever efficiently',\n",
       " \"During life's final moments normally\",\n",
       " 'They balanced themselves in country',\n",
       " 'Yes, the letter came through',\n",
       " \"Oh no, it's feast week\",\n",
       " 'Ensure usual action in region',\n",
       " \"Let's develop green public places\",\n",
       " \"I doubt there's nothing interesting\",\n",
       " \"The doctor's experience is simple\",\n",
       " \"Excuse me, where's the store?\",\n",
       " 'Each moment is quite calm',\n",
       " \"Unfortunately, somebody's in trouble\",\n",
       " 'The bedroom has white bottles',\n",
       " 'Chart your own development path',\n",
       " 'Thank you for fresh color',\n",
       " 'Children enjoy trivial business sometimes',\n",
       " 'Amazing quality community center opened',\n",
       " 'Breath underwater for two minutes',\n",
       " 'Bring the rack to room',\n",
       " 'Did the phone ring again?',\n",
       " \"I'm going to card game\",\n",
       " 'Shall we ensure child safety?',\n",
       " 'The entire day was absolutely heavy',\n",
       " 'Do you have education concerns?',\n",
       " \"Friend, it's just terrible weather\",\n",
       " 'People still need their space',\n",
       " \"I'm feeling fine but tired\",\n",
       " \"Let's meet despite the rain\",\n",
       " 'Those holes need fixing soon',\n",
       " \"Yep, it's a regional issue\",\n",
       " 'The speech was quite interesting',\n",
       " \"Sure, I'll be there forever\",\n",
       " \"It's a terrible day, unfortunately\",\n",
       " \"That's an interesting color combination\",\n",
       " 'Do you doubt your abilities?',\n",
       " \"Let's discuss over breakfast, friend\",\n",
       " 'Bring your own safety gear',\n",
       " 'The community center needs volunteers',\n",
       " 'She stood in front of',\n",
       " \"Let's wait until the other\",\n",
       " \"And I'll use my head\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://audio-language-trainer-private-content/collections/WarmUp150/phrases.json'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLLECTION = \"WarmUp150\"\n",
    "upload_to_gcs(obj=generated_phrases, bucket_name = config.GCS_PRIVATE_BUCKET, file_name = get_phrase_path(collection = COLLECTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_phrases = read_from_gcs(config.GCS_PRIVATE_BUCKET,\n",
    "                                  file_path=get_phrase_path(collection=COLLECTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(generated_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing phrases...: 100%|██████████| 249/249 [06:36<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.nlp import create_flashcard_index\n",
    "\n",
    "WarmUp150_Index = create_flashcard_index(generated_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://audio-language-trainer-private-content/collections/WarmUp150/index.json'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_to_gcs(obj=WarmUp150_Index, bucket_name=config.GCS_PRIVATE_BUCKET, file_name = get_phrase_index_path(collection=COLLECTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove redundant phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.phrase import remove_phrases_with_no_new_words\n",
    "old_list = load_text_file(phrase_dir / \"longman_1000_phrases.txt\")\n",
    "new_list = load_text_file(phrase_dir / \"longman_2000_phrases.txt\")\n",
    "new_list_2 = remove_phrases_with_no_new_words(known_phrases=old_list, new_phrases=new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text_file(new_list_2, phrase_dir / \"longman_2000_phrases.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text_file(line=ordered_phrase_list, file_path = phrase_dir / \"gcse_phrases.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate phrases and vocab for a scenario\n",
    "Use an LLM to come up with typical phrases for a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"meeting new swedish people - language learning community - talking about sweden - hiking, wild swimming, nature\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speaking_phrases = generate_scenario_phrases(scenario, num_phrases=\"20 - 25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_text_file(lines=speaking_phrases, file_path=phrase_dir / \"swedish_language_learning.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk out this scenarios with some vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_phrases = generate_scenario_vocab_building_phrases(scenario=scenario)\n",
    "save_text_file(lines=vocab_phrases, file_path=phrase_dir / \"swedish_lanuage_learning_vocab2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
