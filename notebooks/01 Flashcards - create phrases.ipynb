{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.utils import load_json\n",
    "PAY_FOR_API = True #change to True to run cells that cost money via API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Card Generation 01\n",
    "\n",
    "## Generate english phrases\n",
    "\n",
    "The core way we store vocabularly for generating phrases, and then flashcards, is in a dictionary with two keys. 'verbs' (for verbs in the infinitive form, like 'be', 'run') and 'vocab' (for everything else).\n",
    "\n",
    "The intent is that a vocab list is a core learning requirement (e.g. for an exam), and that it is easier to remember words in the context of common phrases. i.e. learning the phrase 'I want', and separtely learning the noun 'cake' is less efficient than learning the phrase 'I want some cake, please'.\n",
    "\n",
    "Even better if we link that phrase to an image and associated audio. This is the dual-encoding theory of langauge learning and leads to retention and recall benefits.\n",
    "\n",
    "The first step is generating your english phrases from your vocab list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longman corpus\n",
    "\n",
    "A common 'starter' corpus containing core words you should learn in terms of the 1st 1000 words, 2nd 1000 words etc\n",
    "\n",
    "You can replace vocab_dict with any custom made python dictionary with 'verbs' and 'vocab' keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_longman_verb_vocab_dict\n",
    "from src.phrase import generate_phrases_from_vocab_dict\n",
    "\n",
    "file_path = '../data/longman-communication-3000.json' # a specifc format\n",
    "vocab_dict = get_longman_verb_vocab_dict(file_path, \"S2\") #S1 = 1st 1000 words used in Speech, W2 = 2nd 1000 words used in written etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first 10 verbs: ['achieve', 'act', 'address', 'admit', 'advise', 'affect', 'aim', 'announce', 'apologize', 'appear'], \n",
      "and first 10 other words: ['ability', 'abuse', 'access', 'accident', 'accommodation', 'activity', 'address', 'administration', 'adult', 'advance']\n"
     ]
    }
   ],
   "source": [
    "print(f\" first 10 verbs: {vocab_dict['verbs'][:10]}, \\nand first 10 other words: {vocab_dict['vocab'][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating conversational phrases from a vocabulary dictionary\n",
    "\n",
    "This function will iterate through (by sampling) the vocabularly dictionary, until it is exhausted.\n",
    "We run a check against generated phrases so we can 'tick off' words already used.\n",
    "\n",
    "Phrases are generated using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or for GCSE vocab:\n",
    "vocab_dict = load_json(\"..\\data\\gcse_vocab_list_cambridge.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file has been modified. Reloading...\n",
      "Function that called this one: generate_phrases_with_llm. Sleeping for 20 seconds\n",
      "Config file has been modified. Reloading...\n",
      "Iteration 1/1\n",
      "Generated 99 phrases\n",
      "We have 128 verbs and 551 vocab words left\n",
      "Reached maximum number of iterations (1). Stopping phrase generation.\n"
     ]
    }
   ],
   "source": [
    "if PAY_FOR_API:\n",
    "    #comment out the below two lines to go for the default of 6 - 9 word phrases and no more than 2 verbs\n",
    "    length_phrase = \"4-5 words long, for beginner GCSE level, but treat common lexical chunks (I'm going to.., Do you.., Let us.. etc) as a single 'word'\"\n",
    "    verbs_per_phrase = \"one verb (but OK for an additional auxillary verb if necessary)\"\n",
    "    localise = False # whether to tweak the prompt to set phrases within the target country\n",
    "    generated_phrases = generate_phrases_from_vocab_dict(   \n",
    "        vocab_dict, max_iterations=1,\n",
    "         length_phrase=length_phrase,\n",
    "           verbs_per_phrase=verbs_per_phrase,\n",
    "           localise=localise)\n",
    "    #It takes about 15 iterations to go through 200 verbs, 800 vocab (1000 words total)\n",
    "    #You will end up with about 1000 phrases, so get practice of the same verb etc in different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please open the door',\n",
       " 'Do you need help?',\n",
       " \"I'm going to visit Paris\",\n",
       " \"Let's dance in the rain\",\n",
       " \"Don't worry about the test\",\n",
       " 'Can you lend me money?',\n",
       " 'I love eating cheese',\n",
       " 'Shall we shop for clothes?',\n",
       " 'The sun is shining brightly',\n",
       " 'Did you hear the news?',\n",
       " \"I'm trying to lose weight\",\n",
       " \"Let's plan a city trip\",\n",
       " \"Don't forget to pack socks\",\n",
       " 'Can you smell the flowers?',\n",
       " \"We're going to the zoo\",\n",
       " 'Do you want some tea?',\n",
       " 'I need new shoes',\n",
       " \"Let's chat about work\",\n",
       " \"Don't complain about the weather\",\n",
       " 'Can you drive me home?',\n",
       " \"I hope it doesn't rain\",\n",
       " 'Shall we rest a bit?',\n",
       " 'The cake tastes delicious',\n",
       " 'Did they find your keys?',\n",
       " \"I'm learning to cook\",\n",
       " \"Let's climb that hill\",\n",
       " \"Don't smoke in here\",\n",
       " 'Can you accompany me tomorrow?',\n",
       " \"We're going to escape Paris\",\n",
       " 'Do you like French food?',\n",
       " 'I want to learn French',\n",
       " \"Let's visit the Eiffel Tower\",\n",
       " \"Don't forget your umbrella\",\n",
       " 'Can you help me please?',\n",
       " \"I'm trying to stay awake\",\n",
       " 'Shall we get some coffee?',\n",
       " 'The bread smells amazing',\n",
       " 'Did you wash your hands?',\n",
       " \"I'm going to the market\",\n",
       " \"Let's walk in the park\",\n",
       " \"Don't hit the football inside\",\n",
       " 'Can you teach me French?',\n",
       " \"We're going to succeed together\",\n",
       " 'Do you need a dictionary?',\n",
       " 'I love French cheese',\n",
       " \"Let's compare wine prices\",\n",
       " \"Don't worry about the cost\",\n",
       " 'Can you close the window?',\n",
       " \"I'm going to take photos\",\n",
       " 'Shall we watch the sunset?',\n",
       " 'The flowers look beautiful',\n",
       " 'Did you hear that sound?',\n",
       " \"I'm trying to speak French\",\n",
       " \"Let's go to the beach\",\n",
       " \"Don't forget your sunscreen\",\n",
       " 'Can you smell the sea?',\n",
       " \"We're going to Paris tomorrow\",\n",
       " 'Do you like French wine?',\n",
       " 'I want to visit museums',\n",
       " \"Let's try French cuisine\",\n",
       " \"Don't lose your passport\",\n",
       " 'Can you advise me please?',\n",
       " \"I'm going to learn cooking\",\n",
       " 'Shall we buy some bread?',\n",
       " 'The music sounds lovely',\n",
       " 'Did you see the Louvre?',\n",
       " \"I'm trying to wake up\",\n",
       " \"Let's go for a walk\",\n",
       " \"Don't forget your coat\",\n",
       " 'Can you help me pack?',\n",
       " \"We're going to travel soon\",\n",
       " 'Do you speak any French?',\n",
       " 'I love French culture',\n",
       " \"Let's visit a caf√©\",\n",
       " \"Don't worry about directions\",\n",
       " 'Can you order in French?',\n",
       " \"I'm going to make friends\",\n",
       " 'Shall we try some cheese?',\n",
       " 'The city looks beautiful',\n",
       " 'Did you enjoy the concert?',\n",
       " \"I'm trying to find tickets\",\n",
       " \"Let's explore the streets\",\n",
       " \"Don't forget your camera\",\n",
       " 'Can you read this map?',\n",
       " \"We're going to have fun\",\n",
       " 'Do you like French art?',\n",
       " 'I want to see paintings',\n",
       " \"Let's take the metro\",\n",
       " \"Don't lose your ticket\",\n",
       " 'Can you recommend a restaurant?',\n",
       " \"I'm going to send postcards\",\n",
       " 'Shall we buy souvenirs?',\n",
       " 'The view is breathtaking',\n",
       " 'Did you try the croissants?',\n",
       " \"I'm trying to relax\",\n",
       " \"Let's sit in a park\",\n",
       " \"Don't forget to rest\",\n",
       " 'Can you take my picture?',\n",
       " \"We're going to make memories\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save phrases\n",
    "output_dir = \"../outputs\"\n",
    "filename = \"my_phrases.txt\"\n",
    "\n",
    "file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for phrase in generated_phrases:\n",
    "        f.write(phrase + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
