{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "PAY_FOR_API = False #change to True to run cells that cost money via API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Card Generation 01\n",
    "\n",
    "## Generate english phrases\n",
    "\n",
    "The core way we store vocabularly for generating phrases, and then flashcards, is in a dictionary with two keys. 'verbs' (for verbs in the infinitive form, like 'be', 'run') and 'vocab' (for everything else).\n",
    "\n",
    "The intent is that a vocab list is a core learning requirement (e.g. for an exam), and that it is easier to remember words in the context of common phrases. i.e. learning the phrase 'I want', and separtely learning the noun 'cake' is less efficient than learning the phrase 'I want some cake, please'.\n",
    "\n",
    "Even better if we link that phrase to an image and associated audio. This is the dual-encoding theory of langauge learning and leads to retention and recall benefits.\n",
    "\n",
    "The first step is generating your english phrases from your vocab list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longman corpus\n",
    "\n",
    "A common 'starter' corpus containing core words you should learn in terms of the 1st 1000 words, 2nd 1000 words etc\n",
    "\n",
    "You can replace vocab_dict with any custom made python dictionary with 'verbs' and 'vocab' keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_longman_verb_vocab_dict\n",
    "from src.phrase import generate_phrases_from_vocab_dict\n",
    "\n",
    "file_path = '../data/longman-communication-3000.json'\n",
    "vocab_dict = get_longman_verb_vocab_dict(file_path, \"S2\") #S1 = 1st 1000 words used in Speech, W2 = 2nd 1000 words used in written etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" first 10 verbs: {vocab_dict['verbs'][:10]}, \\nand first 10 other words: {vocab_dict['vocab'][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating conversational phrases from a vocabulary dictionary\n",
    "\n",
    "This function will iterate through (by sampling) the vocabularly dictionary, until it is exhausted.\n",
    "We run a check against generated phrases so we can 'tick off' words already used.\n",
    "\n",
    "Phrases are generated using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PAY_FOR_API:\n",
    "    generated_phrases = generate_phrases_from_vocab_dict(vocab_dict, max_iterations=15)\n",
    "    #It takes about 15 iterations to go through 200 verbs, 800 vocab (1000 words total)\n",
    "    #You will end up with about 1000 phrases, so get practice of the same verb etc in different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save phrases\n",
    "output_dir = \"../outputs\"\n",
    "filename = \"my_phrases.txt\"\n",
    "\n",
    "file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for phrase in generated_phrases:\n",
    "        f.write(phrase + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
