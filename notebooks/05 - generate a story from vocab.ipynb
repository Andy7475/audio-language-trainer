{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Generation\n",
    "We remember things better as stories. The plan here is to pick a subset of our phrases, extract the vocabularly, and generate a story based off of them. We can then pull in more flashcards / phrases to ensure a more complete phrase coverage.\n",
    "\n",
    "The story name will be story_some_title; when added as a 'tag' into Anki, this will add a hyperlink to a google cloud bucket of a specific format of bucket/language/story_name/story_name.html\n",
    "\n",
    "This means it is easy to add new stories to an existing flashcard deck, and the links will update as soon as you add the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PAY_FOR_API = True #change to True to run cells that cost money via API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from src.anki_tools import AnkiCollectionReader, get_deck_contents\n",
    "from src.config_loader import config\n",
    "from src.nlp import (\n",
    "    create_flashcard_index,\n",
    "    find_missing_vocabulary,\n",
    "    get_vocab_dict_from_dialogue,\n",
    "    get_vocab_dictionary_from_phrases,\n",
    "    get_index_subset\n",
    ")\n",
    "from src.utils import (\n",
    "    load_json,\n",
    "    load_text_file,\n",
    "    save_json,\n",
    "    save_pickle,\n",
    "    load_pickle,\n",
    "    upload_story_to_gcs,\n",
    "    upload_to_gcs,\n",
    ")\n",
    "\n",
    "from src.phrase import get_phrase_indices\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add directories\n",
    "story images can be re-used between languages, but audio files are language specific, so we structure the story directory story_name/language with audio files in 'language/' and images and the english JSON file in story_name dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path().absolute()  # This gives src/notebooks\n",
    "phrase_dir = notebook_dir.parent / \"data\" / \"phrases\" #where we store text files of phrases\n",
    "story_dir = notebook_dir.parent / \"outputs\" / \"stories\" # where we store our stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we already have flashcards generated for some phrases:\n",
    "a flashcard index allows us to select flashcards that cover a specific vocabulary range, it's quite computationally expensive, but is generated\n",
    "using create_flashcard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASE_LIST_NAME = \"longman_1000_phrases\"\n",
    "phrase_file = phrase_dir / f\"{PHRASE_LIST_NAME}.txt\"\n",
    "phrases = load_text_file(phrase_file)\n",
    "pprint(f\"First few phrases {phrases[:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the flashcard index\n",
    "This makes it very fast to find matching flashcards from a given vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long process, so only create if it doesn't exist\n",
    "notebook_dir = Path().absolute()  # This gives src/notebooks\n",
    "index_file = phrase_dir / f\"{PHRASE_LIST_NAME}_index.json\"\n",
    "\n",
    "if index_file.exists():\n",
    "    phrase_index = load_json(index_file)\n",
    "else:\n",
    "    phrase_index = create_flashcard_index(phrases)\n",
    "    save_json(data=phrase_index, file_path=index_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample some phrases to generate the story from\n",
    "This will pin the story to the vocab found in some pre-existing phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can obtain phrases we know to create a story from:\n",
    "# NOTE: you must close Anki Desktop when trying to form a connection here\n",
    "with AnkiCollectionReader() as reader:\n",
    "    pprint(reader.get_deck_names())\n",
    "\n",
    "#this will print out deck_id : deck_name -> we want to copy the relevant deck_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESTART here to refresh the list of phrases without tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECK_NAME = \"RapidRetention - Swedish::LM1000\"\n",
    "df = get_deck_contents(deck_name=DECK_NAME) #calculates knowledge score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"{df.query(\"tags == ''\").shape[0]} phrases left\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to arrive at all phrases assigned to stories (via tags)\n",
    "So we create an untagged index - an index of flashcards that do not have a tag. We will use these to link to story vocabularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phrases_with_tags = df.query(\"tags != ''\")['EnglishText'].tolist()\n",
    "phrases_without_tags = df.query(\"tags == ''\")['EnglishText'].tolist()\n",
    "#how many words are yet to be assigned to a story?\n",
    "available_vocab = get_vocab_dictionary_from_phrases(phrases_without_tags)\n",
    "print(len(available_vocab['verbs']),  len(available_vocab['vocab']))\n",
    "\n",
    "#we need to know the location of each phrase as an integer in the phrase_index\n",
    "phrases_without_tags_indicies = get_phrase_indices(known_phrases = phrases_without_tags, all_phrases = phrase_index['phrases'])\n",
    "\n",
    "#if we already have a phrase linked to a story, we don't want to retrieve that from the index and link it to a story\n",
    "untagged_index = deepcopy(phrase_index)\n",
    "untagged_index['verb_index'] = get_index_subset(phrases_without_tags_indicies, untagged_index['verb_index'])\n",
    "untagged_index['vocab_index'] = get_index_subset(phrases_without_tags_indicies, untagged_index['vocab_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If generating a new story - random sample some new phrases\n",
    "\n",
    "We want to sample from phrases that have no tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_phrases = random.sample(phrases_without_tags, min(100, len(phrases_without_tags)))\n",
    "\n",
    "#or use sampled_phrases\n",
    "vocab_dict_flashcards = get_vocab_dictionary_from_phrases(sampled_phrases) #75 phrases should give a decent amount of vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dialogue_generation import generate_story\n",
    "\n",
    "story_name, story_dialogue = generate_story(vocab_dict_flashcards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using pre-generated story that we want to assign tags to?\n",
    "Then overwrite the story name and load the json dialogue file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#story_name = \"unexpected_music_project\"\n",
    "clean_story_name = f\"story_{story_name.lower().replace(' ', '_')}\"\n",
    "\n",
    "story_path = story_dir / clean_story_name / f\"{clean_story_name}.json\"\n",
    "\n",
    "#story_dialogue = load_json(story_path)\n",
    "save_json(story_dialogue, story_path)\n",
    "print(f\"saved {clean_story_name} to {story_path}\")\n",
    "\n",
    "vocab_dict_story = get_vocab_dict_from_dialogue(story_dialogue, limit_story_parts=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve flashcards we know that better fit the story vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp import get_matching_flashcards_indexed\n",
    "\n",
    "# Let's find the minimal set of flashcards that we need to learn for the story\n",
    "candidate_flashcards = get_matching_flashcards_indexed(vocab_dict_story, untagged_index)\n",
    "candidate_phrases = [card.get('phrase') for card in candidate_flashcards['selected_cards']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the coverage below, we want stories to stretch learners so 70% ish is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "known_vocab_dict = get_vocab_dictionary_from_phrases(candidate_phrases)\n",
    "missing_vocab = find_missing_vocabulary(vocab_dict_source=known_vocab_dict, vocab_dict_target=vocab_dict_story)\n",
    "missing_vocab_dict = missing_vocab[\"missing_vocab\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now supplement these with any remaining flascards we don't yet know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tags to the flashcard deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We are going to add '{clean_story_name}' tag to {len(candidate_phrases)} phrases withing '{DECK_NAME}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes this needs running twice...\n",
    "from src.anki_tools import add_tag_to_matching_notes\n",
    "\n",
    "updates, errors = add_tag_to_matching_notes(\n",
    "    deck_name=DECK_NAME,\n",
    "    phrases=candidate_phrases,\n",
    "    tag=clean_story_name\n",
    ")\n",
    "\n",
    "print(f\"Updated {updates} notes\")\n",
    "if errors:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in errors:\n",
    "        print(f\"- {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat\n",
    "We can now update phrases without tags at the top of this notebook and generate another story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the story files\n",
    "Once you are happy with the flashcard coverage, you can:\n",
    "* translate and add audio\n",
    "* create the story images\n",
    "* create the story album files (M4a files with synced lyrics)\n",
    "* create the story HTML file using those previous files, and upload to Google Cloud Storage\n",
    "* tag the flascards with the story name...this will then mean you can link to the story from within Anki (the template uses tags to auto-create hyperlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df['TargetText'].sample().values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config_loader import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config._load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get_voice_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import text_to_speech\n",
    "\n",
    "text_to_speech(\"Hej! Hur mår du idag? Jag hoppas att allt är bra med dig. Det är en vacker dag ute, och jag tänkte ta en promenad i parken senare.\", config_language=\"target\", gender=\"MALE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"story_midnight_garden_mystery\"\n",
    "clean_story_name = \"story_workplace_stress_vacation\"\n",
    "# story_unexpected_music_project\n",
    "# story_rainy_football_match \n",
    "# story_unexpected_train_adventure \n",
    "# story_unexpected_marathon_adventure\n",
    "# story_sunset_wedding_blues \n",
    "# story_unexpected_wedding_guests \n",
    "# story_unexpected_career_change\n",
    "# story_unexpected_coffee_adventure\n",
    "# story_unexpected_movie_adventure\n",
    "# story_surprise_hospital_adventure\n",
    "# story_unexpected_power_outage\n",
    "\n",
    "print(f\"About to generate {clean_story_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_path = story_dir / clean_story_name / f\"{clean_story_name}.json\"\n",
    "story_dialogue = load_json(story_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate import add_audio, add_translations\n",
    "\n",
    "story_dialogue_audio = add_translations(story_dialogue)\n",
    "story_dialogue_audio = add_audio(story_dialogue_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has target language content in now so we save in language dir\n",
    "save_pickle(data=story_dialogue_audio, file_path=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.pkl\")\n",
    "#story_dialogue_audio = load_pickle(story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image files for each part of the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.images import generate_and_save_story_images\n",
    "    \n",
    "image_data = generate_and_save_story_images(story_dict=story_dialogue_audio, output_dir = story_dir / clean_story_name, story_name=clean_story_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4A audio files which you will be able to download and play via a media player.\n",
    "They have synced lyrics which can be viewed in the Oto Music Player app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from src.story import create_album_files, generate_index_html\n",
    "\n",
    "FIRST_STORY_PART = list(story_dialogue_audio.keys())[0]\n",
    "#may need to change depending on size of story made and what parts there are\n",
    "album_image = Image.open(story_dir / clean_story_name / f\"{clean_story_name}_{FIRST_STORY_PART}.png\")\n",
    "#create m4a file:\n",
    "create_album_files(story_data_dict=story_dialogue_audio, cover_image=album_image, output_dir=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME, story_name=clean_story_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the main html file - this wraps up the M4A files and image files within it, so it's self-contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.story import create_html_story\n",
    "\n",
    "create_html_story(\n",
    "            story_data_dict=story_dialogue_audio,\n",
    "            image_dir=story_dir / clean_story_name, #the langauge sub-folders will be picked up automatically\n",
    "            story_name=clean_story_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to a public google cloud bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_story_path = story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.html\"\n",
    "assert html_story_path.exists()\n",
    "upload_story_to_gcs(html_file_path=html_story_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update and reupload our index.html - which allows users to navigate all the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_index_html()\n",
    "#will default to public GCS bucket\n",
    "upload_to_gcs(\n",
    "    file_path=\"../outputs/stories/index.html\",\n",
    "    content_type=\"text/html\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [\n",
    "    # \"story_workplace_stress_vacation\",\n",
    "    # \"story_unexpected_music_project\",\n",
    "    # \"story_rainy_football_match\", \n",
    "    # \"story_unexpected_train_adventure\", \n",
    "    # \"story_unexpected_marathon_adventure\",\n",
    "    # \"story_sunset_wedding_blues\", \n",
    "    # \"story_unexpected_wedding_guests\", \n",
    "    \"story_unexpected_career_change\",\n",
    "    \"story_unexpected_coffee_adventure\",\n",
    "    \"story_unexpected_movie_adventure\",\n",
    "    \"story_surprise_hospital_adventure\",\n",
    "    \"story_unexpected_power_outage\"\n",
    "]\n",
    "\n",
    "for clean_story_name in stories:\n",
    "    print(f\"About to generate {clean_story_name}\")\n",
    "    story_path = story_dir / clean_story_name / f\"{clean_story_name}.json\"\n",
    "    story_dialogue = load_json(story_path)\n",
    "    story_dialogue_audio = add_translations(story_dialogue)\n",
    "    story_dialogue_audio = add_audio(story_dialogue_audio)\n",
    "    save_pickle(data=story_dialogue_audio, file_path=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.pkl\")\n",
    "    image_data = generate_and_save_story_images(story_dict=story_dialogue_audio, output_dir = story_dir / clean_story_name, story_name=clean_story_name)\n",
    "    FIRST_STORY_PART = list(story_dialogue_audio.keys())[0]\n",
    "    #may need to change depending on size of story made and what parts there are\n",
    "    album_image = Image.open(story_dir / clean_story_name / f\"{clean_story_name}_{FIRST_STORY_PART}.png\")\n",
    "    #create m4a file:\n",
    "    create_album_files(story_data_dict=story_dialogue_audio, cover_image=album_image, output_dir=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME, story_name=clean_story_name)\n",
    "    create_html_story(\n",
    "            story_data_dict=story_dialogue_audio,\n",
    "            image_dir=story_dir / clean_story_name, #the langauge sub-folders will be picked up automatically\n",
    "            story_name=clean_story_name,\n",
    "        )\n",
    "    html_story_path = story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.html\"\n",
    "    assert html_story_path.exists()\n",
    "    upload_story_to_gcs(html_file_path=html_story_path)\n",
    "    generate_index_html()\n",
    "    #will default to public GCS bucket\n",
    "    upload_to_gcs(\n",
    "        file_path=\"../outputs/stories/index.html\",\n",
    "        content_type=\"text/html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
