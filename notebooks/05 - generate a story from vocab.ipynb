{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Generation\n",
    "We remember things better as stories. The plan here is to pick a subset of our phrases, extract the vocabularly, and generate a story based off of them. We can then pull in more flashcards / phrases to ensure a more complete phrase coverage.\n",
    "\n",
    "The story name will be story_some_title; when added as a 'tag' into Anki, this will add a hyperlink to a google cloud bucket of a specific format of bucket/language/story_name/story_name.html\n",
    "\n",
    "This means it is easy to add new stories to an existing flashcard deck, and the links will update as soon as you add the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PAY_FOR_API = True #change to True to run cells that cost money via API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg path added to system PATH: C:\\Program Files\\ffmpeg-7.0-essentials_build\\bin\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from src.anki_tools import AnkiCollectionReader, get_deck_contents\n",
    "from src.config_loader import config\n",
    "from src.nlp import (\n",
    "    create_flashcard_index,\n",
    "    find_missing_vocabulary,\n",
    "    get_vocab_dict_from_dialogue,\n",
    "    get_vocab_dictionary_from_phrases,\n",
    ")\n",
    "from src.utils import (\n",
    "    load_json,\n",
    "    load_text_file,\n",
    "    save_json,\n",
    "    save_pickle,\n",
    "    load_pickle,\n",
    "    upload_story_to_gcs,\n",
    "    upload_to_gcs,\n",
    ")\n",
    "# Add the parent directory of 'src' to the Python path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add directories\n",
    "story images can be re-used between languages, but audio files are language specific, so we structure the story directory story_name/language with audio files in 'language/' and images and the english JSON file in story_name dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path().absolute()  # This gives src/notebooks\n",
    "phrase_dir = notebook_dir.parent / \"data\" / \"phrases\" #where we store text files of phrases\n",
    "story_dir = notebook_dir.parent / \"outputs\" / \"stories\" # where we store our stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we already have flashcards generated for some phrases:\n",
    "a flashcard index allows us to select flashcards that cover a specific vocabulary range, it's quite computationally expensive, but is generated\n",
    "using create_flashcard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"First few phrases ['a friendly Swedish conversation partner', 'Are there any \"\n",
      " \"Swedish events nearby?', 'Are there any Swedish holidays soon?', 'aromatic \"\n",
      " \"cinnamon buns for fika', 'authentic Swedish pronunciation practice', 'Can \"\n",
      " \"you recommend a Swedish book?', 'Can you suggest any Swedish films?', \"\n",
      " \"'colourful wildflowers in a sunny meadow', 'cosy language exchange meetup', \"\n",
      " \"'Could you explain this Swedish phrase?']\")\n"
     ]
    }
   ],
   "source": [
    "PHRASE_LIST_NAME = \"swedish_language_learning\"\n",
    "phrase_file = phrase_dir / f\"{PHRASE_LIST_NAME}.txt\"\n",
    "phrases = load_text_file(phrase_file)\n",
    "pprint(f\"First few phrases {phrases[:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the flashcard index\n",
    "This makes it very fast to find matching flashcards from a given vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexes phrases...: 100%|██████████| 52/52 [01:06<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# long process, so only create if it doesn't exist\n",
    "notebook_dir = Path().absolute()  # This gives src/notebooks\n",
    "index_file = phrase_dir / f\"{PHRASE_LIST_NAME}_index.json\"\n",
    "\n",
    "if index_file.exists():\n",
    "    phrase_index = load_json(index_file)\n",
    "else:\n",
    "    phrase_index = create_flashcard_index(phrases)\n",
    "    save_json(data=phrase_index, file_path=index_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample some phrases to generate the story from\n",
    "This will pin the story to the vocab found in some pre-existing phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Default',\n",
      " 1731524665442: 'Swedish EAL',\n",
      " 1732020971325: 'RapidRetention - Swedish - LM1000',\n",
      " 1732316149591: 'RapidRetention - Russian - LM1000',\n",
      " 1732316936163: 'RapidRetention - Italian - LM1000',\n",
      " 1732637740663: 'RapidRetention - Welsh - LM1000',\n",
      " 1732980361514: 'RapidRetention - Russian - GCSE',\n",
      " 1732993700879: 'Persian Alphabet',\n",
      " 1734260227418: 'RapidRetention - Swedish - NumbersDays',\n",
      " 1734261644938: 'RapidRetention - Russian - NumbersDays',\n",
      " 1734264578929: 'RapidRetention - Italian - NumbersDays',\n",
      " 1734426251278: 'RapidRetention - French - NumbersDays',\n",
      " 1735660105659: 'RapidRetention - Swedish - EatingOut',\n",
      " 1735684325990: 'RapidRetention - Czech - EatingOut',\n",
      " 1735687489606: 'RapidRetention - Welsh - EatingOut',\n",
      " 1735998451053: 'RapidRetention - Italian - EatingOut',\n",
      " 1737410923009: 'RapidRetention - Swedish - LanguageMeetUp'}\n"
     ]
    }
   ],
   "source": [
    "#we can obtain phrases we know to create a story from:\n",
    "# NOTE: you must close Anki Desktop when trying to form a connection here\n",
    "with AnkiCollectionReader() as reader:\n",
    "    pprint(reader.get_deck_names())\n",
    "\n",
    "#this will print out deck_id : deck_name -> we want to copy the relevant deck_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>n_cards</th>\n",
       "      <th>avg_ease</th>\n",
       "      <th>total_reps</th>\n",
       "      <th>avg_reps</th>\n",
       "      <th>total_lapses</th>\n",
       "      <th>avg_lapses</th>\n",
       "      <th>avg_interval</th>\n",
       "      <th>TargetText</th>\n",
       "      <th>TargetAudio</th>\n",
       "      <th>TargetAudioSlow</th>\n",
       "      <th>EnglishText</th>\n",
       "      <th>WiktionaryLinks</th>\n",
       "      <th>Picture</th>\n",
       "      <th>TargetLanguageName</th>\n",
       "      <th>knowledge_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1737410886674</td>\n",
       "      <td>Language Practice With Images</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>välsliten svensk grammatiklärobok</td>\n",
       "      <td>[sound:3710f25e-8920-424f-82b3-28a5c4cbb42c.mp3]</td>\n",
       "      <td>[sound:7945e360-168c-47c9-8d61-be13f098bec4.mp3]</td>\n",
       "      <td>well-worn Swedish grammar textbook</td>\n",
       "      <td>välsliten &lt;a href=\"https://en.wiktionary.org/w...</td>\n",
       "      <td>&lt;img src=\"f8fcab2a-1821-4337-80dc-9ecd5ddea90e...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1737410886678</td>\n",
       "      <td>Language Practice With Images</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Svenska köttbullar med lingon</td>\n",
       "      <td>[sound:1f3e2c5d-3956-49a3-93f0-6b457f4cea40.mp3]</td>\n",
       "      <td>[sound:600e641d-2c3c-4ed9-99e0-0fee2c726742.mp3]</td>\n",
       "      <td>Swedish meatballs with lingonberries</td>\n",
       "      <td>&lt;a href=\"https://en.wiktionary.org/wiki/svensk...</td>\n",
       "      <td>&lt;img src=\"339cd2f9-f3ce-4eb8-a1ae-77b9a5448ff4...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737410886682</td>\n",
       "      <td>Language Practice With Images</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>autentisk svensk uttalspraxis</td>\n",
       "      <td>[sound:7ddbf66b-dc74-4ede-b673-0188148120a1.mp3]</td>\n",
       "      <td>[sound:57f0b762-db0d-4143-ab8f-4825c2da72bb.mp3]</td>\n",
       "      <td>authentic Swedish pronunciation practice</td>\n",
       "      <td>&lt;a href=\"https://en.wiktionary.org/wiki/autent...</td>\n",
       "      <td>&lt;img src=\"cbed7cf0-8c6b-4fdf-bb1c-c5a71d4fae93...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1737410886686</td>\n",
       "      <td>Language Practice With Images</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mysig språkutbytesträff</td>\n",
       "      <td>[sound:586c6239-d2c8-4e24-94d6-1e81010e399c.mp3]</td>\n",
       "      <td>[sound:1347e7e3-65ab-4f64-a102-5c2f60680957.mp3]</td>\n",
       "      <td>cosy language exchange meetup</td>\n",
       "      <td>&lt;a href=\"https://en.wiktionary.org/wiki/mysig#...</td>\n",
       "      <td>&lt;img src=\"b44ca58d-2e29-481e-8376-236ee8954557...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1737410886690</td>\n",
       "      <td>Language Practice With Images</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Har du besökt Sverige förut?</td>\n",
       "      <td>[sound:095c5937-4b37-412d-8378-e7136061687b.mp3]</td>\n",
       "      <td>[sound:d28d9166-a773-4d86-883d-9a9cabe31885.mp3]</td>\n",
       "      <td>Have you visited Sweden before?</td>\n",
       "      <td>&lt;a href=\"https://en.wiktionary.org/wiki/har#Sw...</td>\n",
       "      <td>&lt;img src=\"8c33fd7e-b6bf-40de-ad72-547103679a57...</td>\n",
       "      <td>Swedish</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         note_id                     model_name tags  n_cards  avg_ease  \\\n",
       "0  1737410886674  Language Practice With Images             3       0.0   \n",
       "1  1737410886678  Language Practice With Images             3       0.0   \n",
       "2  1737410886682  Language Practice With Images             3       0.0   \n",
       "3  1737410886686  Language Practice With Images             3       0.0   \n",
       "4  1737410886690  Language Practice With Images             3       0.0   \n",
       "\n",
       "   total_reps  avg_reps  total_lapses  avg_lapses  avg_interval  \\\n",
       "0           0       0.0             0         0.0           0.0   \n",
       "1           0       0.0             0         0.0           0.0   \n",
       "2           0       0.0             0         0.0           0.0   \n",
       "3           0       0.0             0         0.0           0.0   \n",
       "4           0       0.0             0         0.0           0.0   \n",
       "\n",
       "                          TargetText  \\\n",
       "0  välsliten svensk grammatiklärobok   \n",
       "1      Svenska köttbullar med lingon   \n",
       "2      autentisk svensk uttalspraxis   \n",
       "3            mysig språkutbytesträff   \n",
       "4       Har du besökt Sverige förut?   \n",
       "\n",
       "                                        TargetAudio  \\\n",
       "0  [sound:3710f25e-8920-424f-82b3-28a5c4cbb42c.mp3]   \n",
       "1  [sound:1f3e2c5d-3956-49a3-93f0-6b457f4cea40.mp3]   \n",
       "2  [sound:7ddbf66b-dc74-4ede-b673-0188148120a1.mp3]   \n",
       "3  [sound:586c6239-d2c8-4e24-94d6-1e81010e399c.mp3]   \n",
       "4  [sound:095c5937-4b37-412d-8378-e7136061687b.mp3]   \n",
       "\n",
       "                                    TargetAudioSlow  \\\n",
       "0  [sound:7945e360-168c-47c9-8d61-be13f098bec4.mp3]   \n",
       "1  [sound:600e641d-2c3c-4ed9-99e0-0fee2c726742.mp3]   \n",
       "2  [sound:57f0b762-db0d-4143-ab8f-4825c2da72bb.mp3]   \n",
       "3  [sound:1347e7e3-65ab-4f64-a102-5c2f60680957.mp3]   \n",
       "4  [sound:d28d9166-a773-4d86-883d-9a9cabe31885.mp3]   \n",
       "\n",
       "                                EnglishText  \\\n",
       "0        well-worn Swedish grammar textbook   \n",
       "1      Swedish meatballs with lingonberries   \n",
       "2  authentic Swedish pronunciation practice   \n",
       "3             cosy language exchange meetup   \n",
       "4           Have you visited Sweden before?   \n",
       "\n",
       "                                     WiktionaryLinks  \\\n",
       "0  välsliten <a href=\"https://en.wiktionary.org/w...   \n",
       "1  <a href=\"https://en.wiktionary.org/wiki/svensk...   \n",
       "2  <a href=\"https://en.wiktionary.org/wiki/autent...   \n",
       "3  <a href=\"https://en.wiktionary.org/wiki/mysig#...   \n",
       "4  <a href=\"https://en.wiktionary.org/wiki/har#Sw...   \n",
       "\n",
       "                                             Picture TargetLanguageName  \\\n",
       "0  <img src=\"f8fcab2a-1821-4337-80dc-9ecd5ddea90e...            Swedish   \n",
       "1  <img src=\"339cd2f9-f3ce-4eb8-a1ae-77b9a5448ff4...            Swedish   \n",
       "2  <img src=\"cbed7cf0-8c6b-4fdf-bb1c-c5a71d4fae93...            Swedish   \n",
       "3  <img src=\"b44ca58d-2e29-481e-8376-236ee8954557...            Swedish   \n",
       "4  <img src=\"8c33fd7e-b6bf-40de-ad72-547103679a57...            Swedish   \n",
       "\n",
       "   knowledge_score  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DECK_NAME = \"RapidRetention - Swedish - LanguageMeetUp\"\n",
    "df = get_deck_contents(deck_name=DECK_NAME) #calculates knowledge score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find phrases we know, and limit the flashcard index to those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.phrase import get_phrase_indices\n",
    "\n",
    "known_phrases = df.query(\"knowledge_score > 0.2\").sort_values(by=\"knowledge_score\", ascending=False)['EnglishText'].tolist()\n",
    "\n",
    "#we need to know the location of each phrase as an integer in the phrase_index\n",
    "known_phrase_indicies = get_phrase_indices(known_phrases = known_phrases, all_phrases = phrase_index['phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from src.nlp import remove_unknown_index_values\n",
    "\n",
    "#if we don't know a phrase, we don't want to retrieve that from the index and link it to a story\n",
    "known_index = deepcopy(phrase_index)\n",
    "known_index['verb_index'] = remove_unknown_index_values(known_phrase_indicies, known_index['verb_index'])\n",
    "known_index['vocab_index'] = remove_unknown_index_values(known_phrase_indicies, known_index['vocab_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_phrases = random.sample(known_phrases, min(75, len(known_phrases)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or use sampled_phrases\n",
    "vocab_dict_flashcards = get_vocab_dictionary_from_phrases(phrases) #75 phrases should give a decent amount of vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function that called this one: generate_story. Sleeping for 20 seconds\n",
      "generated story: Swedish Adventure in Winter Wilderness\n"
     ]
    }
   ],
   "source": [
    "from src.dialogue_generation import generate_story\n",
    "\n",
    "story_name, story_dialogue = generate_story(vocab_dict_flashcards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved story to y:\\Python Scripts\\audio-language-trainer\\outputs\\stories\\story_swedish_adventure_in_winter_wilderness\\story_swedish_adventure_in_winter_wilderness.json\n"
     ]
    }
   ],
   "source": [
    "#story_name = \"lost_in_stockholm\"\n",
    "clean_story_name = f\"story_{story_name.lower().replace(' ', '_')}\"\n",
    "story_path = story_dir / clean_story_name / f\"{clean_story_name}.json\"\n",
    "\n",
    "save_json(story_dialogue, story_path)\n",
    "print(f\"saved story to {story_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the LLM goes a bit beyond the vocab found in the flashcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VOCABULARY COVERAGE ANALYSIS ===\n",
      "Target verbs covered by flashcards: 27.0%\n",
      "Target vocabulary covered by flashcards: 44.2%\n",
      "\n",
      "Verbs needing new flashcards:\n",
      "['think', \"'ve\", 'get', 'freeze', 'let'] ...\n",
      "\n",
      "Vocabulary needing new flashcards:\n",
      "['an', 'back', 'really', 'beautiful', 'great'] ...\n"
     ]
    }
   ],
   "source": [
    "vocab_dict_story = get_vocab_dict_from_dialogue(story_dialogue, limit_story_parts=None)\n",
    "vocab_overlap = find_missing_vocabulary(vocab_dict_flashcards, vocab_dict_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve flashcards we know that better fit the story vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average knowledge:  nan\n",
      "=== VOCABULARY COVERAGE ANALYSIS ===\n",
      "Target verbs covered by flashcards: 0.0%\n",
      "Target vocabulary covered by flashcards: 0.0%\n",
      "\n",
      "Verbs needing new flashcards:\n",
      "['think', \"'ve\", 'get', 'freeze', 'let'] ...\n",
      "\n",
      "Vocabulary needing new flashcards:\n",
      "['an', 'snowy', 'back', 'pine', 'great'] ...\n"
     ]
    }
   ],
   "source": [
    "from src.nlp import get_matching_flashcards_indexed\n",
    "\n",
    "# Let's pull all the existing phrases we need to cover the vocab on our story\n",
    "#remember we modified the index to only use flashcards we known\n",
    "known_results = get_matching_flashcards_indexed(vocab_dict_story, known_index)\n",
    "known_flashcards = [card.get('phrase') for card in known_results['selected_cards']]\n",
    "print(\"Average knowledge: \", df.loc[df['EnglishText'].isin(known_flashcards)].knowledge_score.mean())\n",
    "known_vocab_dict = get_vocab_dictionary_from_phrases(known_flashcards)\n",
    "missing_vocab = find_missing_vocabulary(vocab_dict_source=known_vocab_dict, vocab_dict_target=vocab_dict_story)\n",
    "missing_vocab_dict = missing_vocab[\"missing_vocab\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now supplement these with any remaining flascards we don't yet know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should have a higher match in the cell above, we can now draw missing flashcards from the full index\n",
    "\n",
    "additional_results = get_matching_flashcards_indexed(missing_vocab_dict, phrase_index)\n",
    "additional_flashcards = [card.get('phrase') for card in additional_results['selected_cards']]\n",
    "print(len(additional_flashcards))\n",
    "\n",
    "all_flashcards = additional_flashcards + known_flashcards\n",
    "all_flashcards_vocab_dict = get_vocab_dictionary_from_phrases(all_flashcards)\n",
    "final_missing_vocab = find_missing_vocabulary(all_flashcards_vocab_dict, vocab_dict_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We need {len(all_flashcards)} flashcards to cover the story\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the story files\n",
    "Once you are happy with the flashcard coverage, you can:\n",
    "* translate and add audio\n",
    "* create the story images\n",
    "* create the story album files (M4a files with synced lyrics)\n",
    "* create the story HTML file using those previous files, and upload to Google Cloud Storage\n",
    "* tag the flascards with the story name...this will then mean you can link to the story from within Anki (the template uses tags to auto-create hyperlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning translation for introduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations:  33%|███▎      | 1/3 [00:01<00:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated dialogue\n",
      "Beginning translation for development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated dialogue\n",
      "Beginning translation for resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations: 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding audio:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning text-to-speech for introduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dialogue audio: 100%|██████████| 6/6 [00:18<00:00,  3.02s/it]\n",
      "adding audio:  33%|███▎      | 1/3 [00:33<01:06, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech for dialogue done\n",
      "Beginning text-to-speech for development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dialogue audio: 100%|██████████| 7/7 [00:13<00:00,  1.98s/it]\n",
      "adding audio:  67%|██████▋   | 2/3 [00:47<00:22, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech for dialogue done\n",
      "Beginning text-to-speech for resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dialogue audio: 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n",
      "adding audio: 100%|██████████| 3/3 [00:59<00:00, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech for dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.generate import add_audio, add_translations\n",
    "\n",
    "story_dialogue_audio = add_translations(story_dialogue)\n",
    "story_dialogue_audio = add_audio(story_dialogue_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has target language content in now so we save in language dir\n",
    "save_pickle(data=story_dialogue_audio, file_path=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.pkl\")\n",
    "#story_dialogue_audio = load_pickle(story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image files for each part of the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating story images:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function that called this one: create_image_generation_prompt_for_story_part. Sleeping for 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 19/19 [00:19<00:00,  1.01s/it]\u001b[0m\n",
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 15/15 [00:15<00:00,  1.01s/it]\u001b[0m\n",
      "Generating story images:  33%|███▎      | 1/3 [00:50<01:41, 50.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image with imagen using prompt: Looking out over a snow-covered Swedish lakeside from the window of a cozy wooden resort cabin, with distant pine forests and mountains, warm golden light from inside contrasting with the crisp blue winter twilight outside, and a few bundled-up figures visible in the distance enjoying the serene landscape in the style of Studio Ghibli art style, soft atmospheric colors, detailed backgrounds, gentle gradients, natural elements, dreamy lighting, painted textures\n",
      "Successfully generated and saved image for introduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m██████████████\u001b[0m| 8/8 [00:08<00:00,  1.01s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function that called this one: create_image_generation_prompt_for_story_part. Sleeping for 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 19/19 [00:19<00:00,  1.01s/it]\u001b[0m\n",
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 16/16 [00:16<00:00,  1.00s/it]\u001b[0m\n",
      "Generating story images:  67%|██████▋   | 2/3 [01:48<00:55, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image with imagen using prompt: A fog-shrouded pine forest trail in winter, with a small wooden cabin barely visible through the thick mist; the atmosphere is eerie and disorienting, with a sense of isolation and uncertainty pervading the cold, damp air in the style of Studio Ghibli art style, soft atmospheric colors, detailed backgrounds, gentle gradients, natural elements, dreamy lighting, painted textures\n",
      "Successfully generated and saved image for development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m██████████████\u001b[0m| 8/8 [00:08<00:00,  1.00s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function that called this one: create_image_generation_prompt_for_story_part. Sleeping for 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 19/19 [00:19<00:00,  1.01s/it]\u001b[0m\n",
      "Waiting for API cooldown: 100%|\u001b[34m████████████\u001b[0m| 16/16 [00:16<00:00,  1.02s/it]\u001b[0m\n",
      "Generating story images: 100%|██████████| 3/3 [02:47<00:00, 55.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image with imagen using prompt: View from a cozy resort restaurant in Sweden, evening light casting a warm glow on rustic wooden tables set with traditional meatballs and lingonberry sauce, large windows showcasing snow-capped mountains in the distance, a crackling fireplace adding to the comfortable atmosphere in the style of Studio Ghibli art style, soft atmospheric colors, detailed backgrounds, gentle gradients, natural elements, dreamy lighting, painted textures\n",
      "Successfully generated and saved image for resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.images import generate_and_save_story_images\n",
    "    \n",
    "image_data = generate_and_save_story_images(story_dict=story_dialogue_audio, output_dir = story_dir / clean_story_name, story_name=clean_story_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4A audio files which you will be able to download and play via a media player.\n",
    "They have synced lyrics which can be viewed in the Oto Music Player app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating album:  33%|███▎      | 1/3 [00:03<00:06,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved M4A file track number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating album:  67%|██████▋   | 2/3 [00:06<00:03,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved M4A file track number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating album: 100%|██████████| 3/3 [00:09<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved M4A file track number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from src.story import create_album_files, generate_index_html\n",
    "\n",
    "FIRST_STORY_PART = list(image_data.keys())[0]\n",
    "#may need to change depending on size of story made and what parts there are\n",
    "album_image = Image.open(story_dir / clean_story_name / f\"{clean_story_name}_{FIRST_STORY_PART}.png\")\n",
    "#create m4a file:\n",
    "create_album_files(story_data_dict=story_dialogue_audio, cover_image=album_image, output_dir=story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME, story_name=clean_story_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the main html file - this wraps up the M4A files and image files within it, so it's self-contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing HTML data: 100%|██████████| 3/3 [04:12<00:00, 84.09s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML story created at: y:\\Python Scripts\\audio-language-trainer\\outputs\\stories\\story_swedish_adventure_in_winter_wilderness\\Swedish\\story_swedish_adventure_in_winter_wilderness.html\n"
     ]
    }
   ],
   "source": [
    "from src.story import create_html_story\n",
    "\n",
    "create_html_story(\n",
    "            story_data_dict=story_dialogue_audio,\n",
    "            image_dir=story_dir / clean_story_name, #the langauge sub-folders will be picked up automatically\n",
    "            story_name=clean_story_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to a public google cloud bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://storage.googleapis.com/audio-language-trainer-stories/swedish/story_swedish_adventure_in_winter_wilderness/story_swedish_adventure_in_winter_wilderness.html'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_story_path = story_dir / clean_story_name / config.TARGET_LANGUAGE_NAME / f\"{clean_story_name}.html\"\n",
    "assert html_story_path.exists()\n",
    "upload_story_to_gcs(html_file_path=html_story_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update and reupload our index.html - which allows users to navigate all the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://storage.googleapis.com/audio-language-trainer-stories/index.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_index_html()\n",
    "#will default to public GCS bucket\n",
    "upload_to_gcs(\n",
    "    file_path=\"../outputs/stories/index.html\",\n",
    "    content_type=\"text/html\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking stories to flash cards\n",
    "We will use the Anki tag feature. Given a list of english phrases that are required to understand a story, we can tag each of those phrases within a specific Anki Deck.\n",
    "\n",
    "The card template will turn any tag starting story_ into a hyperlink to the public google cloud bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_flashcards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#sometimes this needs running twice...\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manki_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_tag_to_matching_notes\n\u001b[0;32m      4\u001b[0m updates, errors \u001b[38;5;241m=\u001b[39m add_tag_to_matching_notes(\n\u001b[0;32m      5\u001b[0m     deck_name\u001b[38;5;241m=\u001b[39mDECK_NAME,\n\u001b[1;32m----> 6\u001b[0m     phrases\u001b[38;5;241m=\u001b[39m\u001b[43mall_flashcards\u001b[49m,\n\u001b[0;32m      7\u001b[0m     tag\u001b[38;5;241m=\u001b[39mclean_story_name\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m notes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_flashcards' is not defined"
     ]
    }
   ],
   "source": [
    "#sometimes this needs running twice...\n",
    "from src.anki_tools import add_tag_to_matching_notes\n",
    "\n",
    "updates, errors = add_tag_to_matching_notes(\n",
    "    deck_name=DECK_NAME,\n",
    "    phrases=all_flashcards,\n",
    "    tag=clean_story_name\n",
    ")\n",
    "\n",
    "print(f\"Updated {updates} notes\")\n",
    "if errors:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in errors:\n",
    "        print(f\"- {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deck = get_deck_contents(DECK_NAME)\n",
    "df_deck.query(\"tags == @clean_story_name\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should know most of the vocab...\n",
    "df_deck.query(\"tags == @clean_story_name\").knowledge_score.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
