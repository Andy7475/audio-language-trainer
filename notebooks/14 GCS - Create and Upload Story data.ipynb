{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import get_first_n_items\n",
    "from src.story import upload_story_image, prepare_dialogue_with_wiktionary\n",
    "from src.gcs_storage import check_blob_exists, read_from_gcs, upload_to_gcs, get_story_translated_dialogue_path, get_story_dialogue_path\n",
    "from src.translation import review_story_dialogue_translations\n",
    "from src.config_loader import config\n",
    "config.TARGET_LANGUAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Data\n",
    "\n",
    "* based around a story_name which is part of a collection (LM1000 > story_the_birthday_party)\n",
    "* translated dialogue (text file)\n",
    "    * comes from google translate\n",
    "    * added to with Wiktionary links for each utternace ('wiktionary_links')\n",
    "* audio file for each utterance of Sam and Alex\n",
    "* 1 x fast audio file for each story part, introduction etc\n",
    "* an image for each story part\n",
    "* challenges for each story\n",
    "    * from a single challenges.json file for each story\n",
    "    * the customisation is when the challenges.html file gets created as the language name is added into the prompt\n",
    "\n",
    "## Storage overview\n",
    "\n",
    "We want to save the english story dialogue as dialogue.json\n",
    "\n",
    "Then translations by language_name, then each phrase as an audio clip. We might want higher quality audio for the stories e.g. chirp3 voice\n",
    "\n",
    "This allows us to quickly retrieve a phrase based on the bucket name and the phrase key, as well as modify individual phrases for later correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get_voice_models(enum_type=\"stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gcs_storage import get_stories_from_collection\n",
    "\n",
    "all_stories = get_stories_from_collection(collection=\"LM1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop all stories (text)\n",
    "\n",
    "Translate and re-upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop stories and translate\n",
    "from src.gcs_storage import check_blob_exists, get_story_dialogue_path, get_story_translated_dialogue_path\n",
    "from src.dialogue_generation import translate_and_upload_dialogue\n",
    "\n",
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    story_file_path = get_story_dialogue_path(story_name, collection=\"LM1000\")\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=\"LM1000\")\n",
    "    if check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} already translated\")\n",
    "        #continue\n",
    "    story_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, story_file_path)\n",
    "    translate_and_upload_dialogue(story_dialogue, story_name, collection=\"LM1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reivew the translations with anthropic \n",
    "for story_name in tqdm(all_stories[1:], desc=\"Reviewing story translations\"):\n",
    "    # Get the translated dialogue path\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=\"LM1000\")\n",
    "    \n",
    "    # Check if translated dialogue exists\n",
    "    if not check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"No translated dialogue found for {story_name}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Download the translated dialogue\n",
    "    print(f\"Downloading translated dialogue for {story_name}...\")\n",
    "    story_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "\n",
    "    # Review the translations\n",
    "    print(f\"Reviewing translations for {story_name}...\")\n",
    "    reviewed_dialogue = review_story_dialogue_translations(\n",
    "        story_dialogue=story_dialogue, verbose=False\n",
    "    )\n",
    "\n",
    "    #Upload the reviewed translations\n",
    "    print(f\"Uploading reviewed translations for {story_name}...\")\n",
    "    upload_to_gcs(\n",
    "        bucket_name=config.GCS_PRIVATE_BUCKET,\n",
    "        file_name=translated_file_path,\n",
    "        obj=reviewed_dialogue\n",
    "    )\n",
    "    print(f\"Successfully processed {story_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add wiktionary links to each story utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in all_stories[1:]:\n",
    "    print(f\"processing {story_name}\")\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=\"LM1000\")\n",
    "    if not check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} not yet translated\")\n",
    "        continue\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    translated_dialogue_with_links = prepare_dialogue_with_wiktionary(translated_dialogue)\n",
    "    # now re-upload it with embedded witkionary_links\n",
    "    uploaded = upload_to_gcs(obj=translated_dialogue_with_links, bucket_name=config.GCS_PRIVATE_BUCKET, file_name=translated_file_path)\n",
    "    print(f\"uploaded {story_name} : {uploaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate audio and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate audio and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through stories to generate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import generate_dialogue_audio_and_upload\n",
    "for story_name in all_stories[1:]:\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(story_name, collection=\"LM1000\")\n",
    "\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    generate_dialogue_audio_and_upload(translated_dialogue, story_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Audio \n",
    "1 file for each story part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import generate_and_upload_fast_audio\n",
    "\n",
    "for story_name in tqdm(all_stories[1:]):\n",
    "    # uploads 1 fast mp3 file for each story part. \n",
    "    generate_and_upload_fast_audio(story_name, collection=\"LM1000\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload images\n",
    "For when we have them stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in all_stories:\n",
    "    notebook_dir = Path().absolute()  # This gives src/notebooks\n",
    "    story_dir = notebook_dir.parent / \"outputs\" / \"stories\"\n",
    "    # get the dialogue\n",
    "    story_file_path = get_story_dialogue_path(story_name, collection=\"LM1000\")\n",
    "    story_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, story_file_path)\n",
    "    for story_part in story_dialogue:\n",
    "        image_file = story_dir / story_name / f\"{story_name}_{story_part}.png\"\n",
    "        assert image_file.exists()\n",
    "        upload_story_image(image_file, story_part, story_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chat import get_html_challenge_inputs, create_html_challenges\n",
    "from src.gcs_storage import upload_to_gcs, get_story_challenges_path, get_story_translated_challenges_path, read_from_gcs\n",
    "\n",
    "for story_name in all_stories[1:]:\n",
    "\n",
    "    challenge_file_path = get_story_challenges_path(story_name, collection=\"LM1000\")\n",
    "    scenario_dicts = read_from_gcs(bucket_name=config.GCS_PRIVATE_BUCKET, file_path=challenge_file_path)\n",
    "    challenges = get_html_challenge_inputs(scenario_dicts)\n",
    "    chat_webpage_file = create_html_challenges(challenges, story_name=story_name) # this creates and uploades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
