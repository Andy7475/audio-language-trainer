{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.story import prepare_dialogue_with_wiktionary\n",
    "from src.translation import review_story_dialogue_translations\n",
    "from src.gcs_storage import (\n",
    "    check_blob_exists,\n",
    "    read_from_gcs,\n",
    "    upload_to_gcs,\n",
    "    get_story_translated_dialogue_path,\n",
    "    get_story_dialogue_path,\n",
    ")\n",
    "from src.config_loader import config\n",
    "\n",
    "print(config.TARGET_LANGUAGE_NAME)\n",
    "COLLECTION = \"LM1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config._load_config()\n",
    "language_name = config.TARGET_LANGUAGE_NAME.lower()\n",
    "print(language_name)\n",
    "config.get_voice_models(enum_type=\"stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gcs_storage import get_stories_from_collection\n",
    "\n",
    "all_stories = get_stories_from_collection(collection=COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stories[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop all stories (text)\n",
    "\n",
    "Translate and re-upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop stories and translate\n",
    "from src.dialogue_generation import translate_and_upload_dialogue\n",
    "\n",
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    story_file_path = get_story_dialogue_path(story_name, collection=COLLECTION)\n",
    "    translated_file_path = get_story_translated_dialogue_path(\n",
    "        story_name, collection=COLLECTION\n",
    "    )\n",
    "    if check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} already translated\")\n",
    "        # continue\n",
    "    story_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, story_file_path)\n",
    "    translate_and_upload_dialogue(story_dialogue, story_name, collection=COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review translations with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in all_stories:\n",
    "    print(f\"processing {story_name}\")\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(\n",
    "        story_name, collection=COLLECTION\n",
    "    )\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    reviewed_dialogue = review_story_dialogue_translations(translated_dialogue)\n",
    "    upload_to_gcs(\n",
    "        obj=reviewed_dialogue,\n",
    "        bucket_name=config.GCS_PRIVATE_BUCKET,\n",
    "        file_name=translated_file_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add wiktionary links to each story utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in all_stories:\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(\n",
    "        story_name, collection=COLLECTION\n",
    "    )\n",
    "    if not check_blob_exists(config.GCS_PRIVATE_BUCKET, translated_file_path):\n",
    "        print(f\"{story_name} not yet translated\")\n",
    "        continue\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    translated_dialogue_with_links = prepare_dialogue_with_wiktionary(\n",
    "        translated_dialogue\n",
    "    )\n",
    "    # now re-upload it with embedded witkionary_links\n",
    "    upload_to_gcs(\n",
    "        obj=translated_dialogue_with_links,\n",
    "        bucket_name=config.GCS_PRIVATE_BUCKET,\n",
    "        file_name=translated_file_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate audio and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate audio and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through stories to generate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import generate_dialogue_audio_and_upload\n",
    "\n",
    "for story_name in all_stories[7:]:\n",
    "    # get the dialogue\n",
    "    translated_file_path = get_story_translated_dialogue_path(\n",
    "        story_name, collection=COLLECTION\n",
    "    )\n",
    "\n",
    "    translated_dialogue = read_from_gcs(config.GCS_PRIVATE_BUCKET, translated_file_path)\n",
    "    generate_dialogue_audio_and_upload(\n",
    "        translated_dialogue, story_name, collection=COLLECTION, overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Audio \n",
    "1 file for each story part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.audio_generation import generate_and_upload_fast_audio\n",
    "\n",
    "for story_name in tqdm(all_stories):\n",
    "    # uploads 1 fast mp3 file for each story part.\n",
    "    generate_and_upload_fast_audio(story_name, collection=COLLECTION, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chat import get_html_challenge_inputs, create_html_challenges\n",
    "from src.gcs_storage import upload_to_gcs, get_story_challenges_path, read_from_gcs\n",
    "\n",
    "for story_name in all_stories:\n",
    "    challenge_file_path = get_story_challenges_path(story_name, collection=COLLECTION)\n",
    "    scenario_dicts = read_from_gcs(\n",
    "        bucket_name=config.GCS_PRIVATE_BUCKET, file_path=challenge_file_path\n",
    "    )\n",
    "    challenges = get_html_challenge_inputs(scenario_dicts)\n",
    "    chat_webpage_file = create_html_challenges(\n",
    "        challenges, story_name=story_name, collection=COLLECTION\n",
    "    )  # this creates and uploades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = \"LM1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
