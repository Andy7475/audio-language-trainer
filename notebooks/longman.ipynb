{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory of 'src' to the Python path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longman phrase and anki deck generation\n",
    "A more memorable way to learn the core vocabulary as defined in Longman Communications vocab lists, we take the vocab and use an LLM\n",
    "to generate phrases using it.\n",
    "\n",
    "## Longman 1000, 2000 and 3000 already provided\n",
    "Enlish phrases for the longman vocab have already been created and can be found in the 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_longman_verb_vocab_dict\n",
    "from src.phrase import generate_phrases_from_vocab_dict\n",
    "\n",
    "file_path = '../data/longman-communication-3000.json'\n",
    "vocab_dict = get_longman_verb_vocab_dict(file_path, \"S3\") #S1 = 1st 1000 words used in Speech, options are S1-3 and W1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/15\n",
      "Generated 101 phrases\n",
      "We have 127 verbs and 728 vocab words left\n",
      "Iteration 2/15\n",
      "Generated 106 phrases\n",
      "We have 58 verbs and 660 vocab words left\n",
      "Iteration 3/15\n",
      "Generated 105 phrases\n",
      "We have 3 verbs and 594 vocab words left\n",
      "Iteration 4/15\n",
      "Generated 98 phrases\n",
      "We have 195 verbs and 520 vocab words left\n",
      "Iteration 5/15\n",
      "Generated 105 phrases\n",
      "We have 112 verbs and 434 vocab words left\n",
      "Iteration 6/15\n",
      "Generated 103 phrases\n",
      "We have 43 verbs and 344 vocab words left\n",
      "Iteration 7/15\n",
      "Generated 87 phrases\n",
      "We have 2 verbs and 307 vocab words left\n",
      "Iteration 8/15\n",
      "Generated 99 phrases\n",
      "We have 250 verbs and 272 vocab words left\n",
      "Iteration 9/15\n",
      "Generated 101 phrases\n",
      "We have 173 verbs and 232 vocab words left\n",
      "Iteration 10/15\n",
      "Generated 109 phrases\n",
      "We have 95 verbs and 161 vocab words left\n",
      "Iteration 11/15\n",
      "Generated 100 phrases\n",
      "We have 37 verbs and 136 vocab words left\n",
      "Iteration 12/15\n",
      "Generated 60 phrases - with minimal phrase prompt\n",
      "We have 30 verbs and 25 vocab words left\n",
      "Iteration 13/15\n",
      "Generated 7 phrases - with minimal phrase prompt\n",
      "We have 29 verbs and 0 vocab words left\n",
      "All words have been used. Phrase generation complete.\n"
     ]
    }
   ],
   "source": [
    "#uses LLM calls - it sometimes generates phrases terminated too early (e.g. Mind the pot on the), so advise you scan through and check\n",
    "\n",
    "#english phrases only initially\n",
    "longman_phrases = generate_phrases_from_vocab_dict(vocab_dict, max_iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/longman/longman_3000_phrases.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for phrase in longman_phrases:\n",
    "        f.write(phrase + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Anki deck from thoses phrases\n",
    "\n",
    "Or, load one of the english Longman phrase lists in data/ already created and apply to your language\n",
    "\n",
    "This function:\n",
    "1. translates\n",
    "2. generates audio using text to speech\n",
    "3. packages up the text and audio into several anki decks (in batches), that can be imported into Anki.\n",
    "\n",
    "The deck_name will is used to derive the deck_id and so despite there being several *.apkg files created, these will all merge successfully into the same deck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning translation for anki\n",
      "Translated phrases\n",
      "\n",
      "Text-to-speech for phrases done\n",
      "\n",
      "Anki deck exported to ../outputs/longman\\longman_3000_0_anki_deck.apkg\n",
      "Cleanup of temporary MP3 files completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.anki import create_anki_deck_from_english_phrase_list\n",
    "\n",
    "_ = await create_anki_deck_from_english_phrase_list(longman_phrases[:3], deck_name=\"Longman 3000 - Swedish\", anki_filename_prefix=\"longman_3000_swedish\", batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import create_image_generation_prompt\n",
    "\n",
    "\n",
    "prompt = create_image_generation_prompt(longman_phrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lazy engineer dared to repair the cooker.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longman_phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Create a vivid, memorable image for language learners based on the following description:\n",
      "    \n",
      "    An exhausted-looking engineer in wrinkled clothes and messy hair, slouching on a couch with a half-eaten pizza nearby. Next to the couch is a broken cooker with its parts scattered around. The engineer is lazily reaching towards the cooker with a screwdriver, barely extending their arm. The room has a warm, dim lighting, creating a cozy yet slightly chaotic atmosphere. The engineer's facial expression shows a mix of reluctance and determination.\n",
      "    \n",
      "    The image should be:\n",
      "    - Colorful and engaging\n",
      "    - Styled like a modern, slightly stylized illustration (not photorealistic)\n",
      "    - Suitable for display on a mobile phone screen (square 1:1 aspect ratio)\n",
      "    - Clear and easily understandable at a glance\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b50730cc654dddb627fa483af2e328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:982: UserWarning: Not enough free disk space to download the file. The expected file size is: 5135.15 MB. The target location C:\\Users\\i5\\.cache\\huggingface\\hub\\models--stabilityai--stable-diffusion-xl-base-1.0\\blobs only has 3012.16 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbfb9c10c4643eaaca19edcfa7f2165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0e31a1318456e8948d00c912116f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58814588800f4639b30944fec296fe6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a35c0ce10a4acba42a854315edd61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de79f2169b43420fa0bb20afbbfca3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\i5\\.cache\\huggingface\\hub\\models--stabilityai--stable-diffusion-xl-base-1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "prompt = \"An astronaut riding a green horse\"\n",
    "\n",
    "images = pipe(prompt=prompt).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a2858b846b4d2da6a58c42d2d348ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu117\"])\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"diffusers\", \"transformers\", \"accelerate\"])\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\" #\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "#model_id = \"stabilityai/stable-diffusion-xl-base-1.0\" #\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298356eb0e1f4b799f6f3960f0841837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Generate an image\n",
    "prompt = \"An exhausted engineer on a couch with a half-eaten pizza nearby. Next to the couch is a broken cooker with its parts scattered around\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
