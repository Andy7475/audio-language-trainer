{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "PAY_FOR_API = True #change to True to run cells that cost money via API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Card Generation 03\n",
    "\n",
    "## Generate flash cards\n",
    "\n",
    "The english phrases (01 notebook) and images (02 notebook) can now be re-used on whatever language you want.\n",
    "\n",
    "The translation and audio generation gets done at the same time as exporting to our unique RapidRetain flash card format.\n",
    "\n",
    "_IMPORTANT_\n",
    "\n",
    "If you are learning more than one language, to prevent memory interference, you should use a different set of images with each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load phrases\n",
    "\n",
    "I've already generated some phrases using the longman corpus from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"First few phrases ['Do you want to become a famous writer?', 'Let me show \"\n",
      " \"you around the city', 'We need to handle this situation carefully', 'Stop \"\n",
      " 'wasting time on this\\', \\'Do you like playing the guitar at night?\\', \"I\\'m '\n",
      " 'taking a vacation next month\", \"Don\\'t forget to wear a helmet while '\n",
      " 'cycling\", \"Let\\'s cut unnecessary expenses this year\", \"We\\'re producing a '\n",
      " 'new product soon\", \\'Did you remember to turn off the stove?\\']')\n"
     ]
    }
   ],
   "source": [
    "from src.anki_tools import create_anki_deck_from_english_phrase_list, export_to_anki_with_images\n",
    "from src.utils import load_text_file, save_json, load_json\n",
    "from src.config_loader import config\n",
    "from pprint import pprint\n",
    "\n",
    "filepath = \"../data/longman_1000_phrases.txt\"\n",
    "phrases = load_text_file(filepath)\n",
    "pprint(f\"First few phrases {phrases[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the flash cards\n",
    "\n",
    "The main function (under the hood) is export_to_anki_with_images()\n",
    "An earlier version of the code created flashcards without images (export_to_anki)\n",
    "\n",
    "Assuming you ran notebook 02 against your phrases, then this next step is a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Love your neighbors as yourself',\n",
      " 'Cover your face with your hands',\n",
      " 'Want to go on a camping trip?',\n",
      " \"Don't you think unity is crucial right now?\",\n",
      " 'Use the glue to make it stick firmly',\n",
      " 'We have to tell the truth about what happened',\n",
      " \"We're selling our old car soon\",\n",
      " 'Are you ready for the big event tomorrow?',\n",
      " 'Press the red button to start',\n",
      " 'Add some spice to make the dish tastier']\n",
      "VoiceInfo(name='en-GB-Studio-B', provider=<VoiceProvider.GOOGLE: 'google'>, voice_type=<VoiceType.STUDIO: 'studio'>, gender='MALE', language_code='en-GB', country_code='GB', voice_id='en-GB-Studio-B')\n",
      "VoiceInfo(name='cmn-CN-Wavenet-A', provider=<VoiceProvider.GOOGLE: 'google'>, voice_type=<VoiceType.WAVENET: 'wavenet'>, gender='FEMALE', language_code='cmn-CN', country_code='CN', voice_id='cmn-CN-Wavenet-A')\n",
      "VoiceInfo(name='cmn-CN-Wavenet-B', provider=<VoiceProvider.GOOGLE: 'google'>, voice_type=<VoiceType.WAVENET: 'wavenet'>, gender='MALE', language_code='cmn-CN', country_code='CN', voice_id='cmn-CN-Wavenet-B')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "config._load_config() #worth doing if you are switching between languages etc\n",
    "image_dir = \"../data/longman_phrase_images/longman1000\"\n",
    "anki_output_dir = f\"../outputs/flashcards/{config.TARGET_LANGUAGE_NAME.lower()}\"\n",
    "deck_name = f\"RapidRetention - {config.TARGET_LANGUAGE_NAME} - LM1000\" #this is used to genearte the Deck ID in Anki\n",
    "anki_filename_prefix = f\"longman_1000_{config.TARGET_LANGUAGE_NAME.lower()}\"\n",
    "sample_phrases = random.sample(phrases, k=10)\n",
    "pprint(sample_phrases)\n",
    "voice_models = config.get_voice_models()\n",
    "for vm in voice_models:\n",
    "    print(vm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'script_dir': 'y:\\\\Python Scripts\\\\audio-language-trainer\\\\src',\n",
       " 'config_file': 'y:\\\\Python Scripts\\\\audio-language-trainer\\\\src\\\\config.json',\n",
       " 'config': namespace(SOURCE_LANGUAGE_CODE='en-GB',\n",
       "           TARGET_LANGUAGE_CODE='cmn-CN',\n",
       "           USE_CHEAP_VOICE_MODELS=False,\n",
       "           ANTHROPIC_MODEL_NAME='claude-3-5-sonnet@20240620',\n",
       "           ANTHROPIC_SMALL_MODEL_NAME='claude-3-haiku@20240307',\n",
       "           ANTHROPIC_REGION='europe-west1',\n",
       "           STABILITY_ENDPOINT='https://api.stability.ai/v2beta/stable-image/generate/core',\n",
       "           THINKING_GAP_MS=3000,\n",
       "           SPEAKING_RATE_SLOW=0.85,\n",
       "           WORD_BREAK_MS=250,\n",
       "           PROJECT_NUMBER=307643465852,\n",
       "           PROJECT_ID='swedish-course',\n",
       "           VERTEX_REGION='us-central1',\n",
       "           TTS_REGION='us-central1',\n",
       "           MAX_TTS_REQUESTS_PER_MINUTE=100,\n",
       "           GRAMMAR_USAGE_PATH='../data/grammar_concepts_usage.json',\n",
       "           VOCAB_USAGE_PATH='../data/1000_vocab_usage.json',\n",
       "           VOCAB_LIST='../data/1000_vocab_list.json',\n",
       "           GRAMMAR_CONCEPTS='../data/grammar_concepts.json',\n",
       "           API_DELAY_SECONDS=20,\n",
       "           TARGET_LANGUAGE_ALPHA2='cmn',\n",
       "           TARGET_LANGUAGE_NAME='Mandarin Chinese',\n",
       "           SOURCE_LANGUAGE_ALPHA2='en',\n",
       "           SOURCE_LANGUAGE_NAME='English'),\n",
       " '_last_load_time': 1732464521.0565352,\n",
       " '_file_modified_time': 1732463520.9340024,\n",
       " 'voice_manager': <src.config_loader.VoiceManager at 0x25bbebc4d90>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning translation for anki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding translations:   0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'TARGET_LANGUAGE_ALPHA2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PAY_FOR_API:\n\u001b[1;32m----> 2\u001b[0m   anki_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_anki_deck_from_english_phrase_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_phrases\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mdeck_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeck_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43manki_filename_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manki_filename_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#saves in batches of 50 notes per apkg file - useful for very large decks to split up\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manki_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#this is where our images are stored\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32my:\\Python Scripts\\audio-language-trainer\\src\\anki_tools.py:528\u001b[0m, in \u001b[0;36mcreate_anki_deck_from_english_phrase_list\u001b[1;34m(phrase_list, deck_name, anki_filename_prefix, batch_size, output_dir, image_dir)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes a list of english phrases and does: 1) translation 2) text to speech 3) export to Anki deck.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03mTo avoid overloading the text-to-speech APIs it will batch up the phrases into smaller decks (*.apkg), but these will all have the same 'deck_id'\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03mand so when you import them into Anki they will merge into the same deck. The decks will be called {anki_filename_prefix}_{from_index}.apkg\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    525\u001b[0m phrase_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manki\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected_phrase_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: phrase_list}\n\u001b[0;32m    527\u001b[0m }  \u001b[38;5;66;03m# this format is because it's the same as our story_dictionary\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m translated_phrases_dict \u001b[38;5;241m=\u001b[39m \u001b[43madd_translations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphrase_dict\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# this already batches so can pass entire list\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# we will now create slices of the main phrase dictionary using a 'from_index' and batch_size\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m from_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(phrase_list), batch_size):\n",
      "File \u001b[1;32my:\\Python Scripts\\audio-language-trainer\\src\\generate.py:161\u001b[0m, in \u001b[0;36madd_translations\u001b[1;34m(story_data_dict)\u001b[0m\n\u001b[0;32m    159\u001b[0m     story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_dialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m translated_dialogue\n\u001b[0;32m    160\u001b[0m corrected_phrase_list \u001b[38;5;241m=\u001b[39m story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected_phrase_list\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 161\u001b[0m translated_phrase_list \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_phrases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrected_phrase_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_phrase_list\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m translated_phrase_list\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated phrases\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32my:\\Python Scripts\\audio-language-trainer\\src\\translation.py:58\u001b[0m, in \u001b[0;36mtranslate_phrases\u001b[1;34m(corrected_phrases)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_phrases\u001b[39m(corrected_phrases: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"translates a list of english phrases and returns a tuple of english, target_language\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    phrases back as this is an easier format to pass into audio generation, and to manually inspect\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     translated_phrases \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrected_phrases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(corrected_phrases, translated_phrases))\n",
      "File \u001b[1;32my:\\Python Scripts\\audio-language-trainer\\src\\translation.py:16\u001b[0m, in \u001b[0;36mbatch_translate\u001b[1;34m(texts, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size):\n\u001b[0;32m     14\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m     15\u001b[0m     result \u001b[38;5;241m=\u001b[39m translate\u001b[38;5;241m.\u001b[39mClient()\u001b[38;5;241m.\u001b[39mtranslate(\n\u001b[1;32m---> 16\u001b[0m         batch, target_language\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTARGET_LANGUAGE_ALPHA2\u001b[49m, source_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m     translated_texts\u001b[38;5;241m.\u001b[39mextend([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslatedText\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_texts\n",
      "File \u001b[1;32my:\\Python Scripts\\audio-language-trainer\\src\\config_loader.py:349\u001b[0m, in \u001b[0;36mConfigLoader.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Delegate attribute access to config object after checking reload\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_reload()  \u001b[38;5;66;03m# Using direct attribute access\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'TARGET_LANGUAGE_ALPHA2'"
     ]
    }
   ],
   "source": [
    "\n",
    "if PAY_FOR_API:\n",
    "  anki_data = create_anki_deck_from_english_phrase_list(phrase_list=sample_phrases[:2],\n",
    "                                                      deck_name = deck_name,\n",
    "                                                      anki_filename_prefix=anki_filename_prefix,\n",
    "                                                      batch_size=50, #saves in batches of 50 notes per apkg file - useful for very large decks to split up\n",
    "                                                      output_dir=anki_output_dir,\n",
    "                                                      image_dir=image_dir #this is where our images are stored\n",
    "                                                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing / Development\n",
    "The anki_data is a dictionary which contains all translations, and audio, you can re-use this to save on API costs if iterating over flashcard design / testing, or if you want to save the data, and create the flashcards later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing story parts: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.images import add_image_paths\n",
    "\n",
    "anki_data = add_image_paths(anki_data, image_dir=image_dir) #adds the image directory filepaths to the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating image and sound files: 10it [00:17,  1.76s/it]\n",
      "adding notes to deck: 100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anki deck exported to ../outputs/flashcards/french\\longman_1000_french_anki_deck.apkg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deleting temp files: 100%|██████████| 30/30 [00:00<00:00, 3748.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup of temporary files completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "export_to_anki_with_images(anki_data,\n",
    "                           output_dir= anki_output_dir,\n",
    "                           story_name=anki_filename_prefix,\n",
    "                           deck_name=deck_name )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
