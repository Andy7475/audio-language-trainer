{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "import ipywidgets as widgets\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the parent directory of 'src' to the Python path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from src.dialogue_generation import get_vocab_from_dialogue, update_vocab_usage\n",
    "from src.dialogue_generation import generate_story_plan, generate_dialogue_prompt, generate_dialogue, generate_recap\n",
    "from src.audio_generation import  text_to_speech, play_audio, generate_audio_from_dialogue, generate_normal_and_fast_audio, generate_translated_phrase_audio, join_audio_segments, export_audio\n",
    "from src.phrase import correct_phrases, generate_practice_phrases_from_dialogue\n",
    "from src.initialise import initialise_usage_data\n",
    "from src.utils import save_json, convert_defaultdict, save_defaultdict, load_json, create_pdf_booklet\n",
    "from src.translation import translate_dialogue, translate_phrases\n",
    "\n",
    "STORY_DATA_PATH = \"../outputs/story_data.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Google Cloud credentials and prerequisites\n",
    "You will need a Google Project with the following APIs enabled:\n",
    "* Text to Speech\n",
    "* Translate\n",
    "* Vertex AI with the following Anthropic models enabled (from the model garden)\n",
    "    * Sonnet 3.5\n",
    "    * Haiku\n",
    "* Add your GOOGLE_PROJECT_ID to the .env file\n",
    "\n",
    "You should alter src/config.json which contains your target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Language Trainer Workflow\n",
    "\n",
    "The aim of this project is to create audio material for you to practise a foreign language. It needs to be engaging and be tailored to words you want to practise. \n",
    "\n",
    "The overall steps we follow are:\n",
    "\n",
    "1. Create an outline story plan based on a theme you select (e.g. 'an adventure', 'a holiday in Rome'). An LLM produces a story plan following a typical story arc (exposition, rising action, climax, falling action, resolution). This ensures an engaging plot.\n",
    "2. Flesh out the story using your practice vocabulary and grammatical concepts. Vocab and concepts are sampled from lists you provide in the 'data' folder (vocab_usage.json and grammar_concepts_usage.json), with sampling being skewed towards words you haven't heard yet. The output here is a dialogue between two people (Sam and Alex).\n",
    "\n",
    "Recaps are generated between each story part so when the LLM generates the next dialogue it logically continues from the previous one.\n",
    "\n",
    "3. The dialogue is broken up into shorter practice phrases via a 'language graph' concept, so we give you not just the long-form dialogue to listen and practise to, but smaller, mixed-up phrases based on the vocab in the story, starting small and buliding to more complex phrases.\n",
    "4. Your vocab list is updated based on the produced dialogue.\n",
    "5. The smaller phrases and main dialogue are translated into your target language and convert to speech.\n",
    "6. Research shows that listening to double-speed audio (on words you already known) can help with your listening comprehension for a foreign language (it helps the brain with the ability to separate distinct words). We therefore create a fast version of the dialogue for listening practice.\n",
    "7. The audio files are stiched together to create an MP3 file for each part in the story (there are 5 parts to the story). The stages for each audio lesson are: \n",
    "* dialogue in the target language\n",
    "* practice phrases of the form 'how do you say: \"practice phrase' in 'target language'?\". A pause (where you speak in the foreign language), then the correct translation is played twice, first fast, then slow.\n",
    "* repeat of the dialogue in the target language so you can satisfy yourself you understand it properly\n",
    "* 12 repeated playings of the fast version of the dialogue to improve your listening comprehension.\n",
    "\n",
    "The intent is then you would listen to the next audio lesson in the story.\n",
    "\n",
    "\n",
    "## Setup your vocab and grammatical concepts\n",
    "You should populate or edit\n",
    "* known_vocab_list.json \n",
    "* grammar_concepts.json\n",
    "\n",
    "### Initiliase the vocab and grammar counters\n",
    "This creates vocab_usage.json (setting all values to 0) and grammar_concepts_usage.json (setting all values to 'true' and counts to 0)\n",
    "\n",
    "You can tweak these to minimise what words and concepts you are exposed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/grammar_concepts_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n"
     ]
    }
   ],
   "source": [
    "initialise_usage_data(overwrite=False) #the overwrite commands stops you wiping all your usage data if it already exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Being Lesson Generation\n",
    "\n",
    "## Create a story plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../outputs/story_plan.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exposition': 'Alex and Sam are exchange students sharing an apartment in a foreign city. They notice strange noises coming from the apartment next door late at night.',\n",
       " 'rising_action': \"The two friends decide to investigate the mysterious sounds. They start asking neighbors for information and observing the apartment's occupants.\",\n",
       " 'climax': 'One night, Alex and Sam follow their neighbor to an abandoned building where they witness a secret meeting.',\n",
       " 'falling_action': 'Confused and worried, they debate whether to inform the authorities or confront their neighbor directly. They gather more evidence about the secret activities.',\n",
       " 'resolution': 'Alex and Sam discover their neighbor is organizing surprise language exchange events for international students. They join the group and make new friends from around the world.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_plan = generate_story_plan(story_guide = \"a mystery\", test = False) #the test parameter will provide pre-canned responses avoiding LLM costs\n",
    "story_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all dialogue\n",
    "\n",
    "1. Create dialouge LLM prompt based on the story part\n",
    "2. LLM generates dialogue\n",
    "3. LLM generates recap\n",
    "4. move to next story part and repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAY_FOR_LLM = True\n",
    "\n",
    "if PAY_FOR_LLM:\n",
    "    story_data_dict = defaultdict(lambda: defaultdict(str))\n",
    "    recap = \"This is the beginning of the story.\"\n",
    "    for step, story_part in enumerate(list(story_plan.keys())):\n",
    "        prompt = generate_dialogue_prompt(story_part=story_part,\n",
    "                                        story_part_outline=story_plan[story_part],\n",
    "                                        last_recap = recap,\n",
    "                                        verb_count=10,\n",
    "                                        verb_use_count=5,\n",
    "                                        vocab_count=30,\n",
    "                                        vocab_use_count=10,\n",
    "                                        grammar_concept_count=5,\n",
    "                                        grammar_use_count=3)\n",
    "        dialogue = generate_dialogue(prompt)\n",
    "        recap = generate_recap(dialogue, test=False)\n",
    "        story_data_dict[story_part][\"dialogue_generation_prompt\"] = prompt\n",
    "        story_data_dict[story_part][\"dialogue\"] = dialogue\n",
    "        story_data_dict[story_part][\"recap\"] = recap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../outputs/story_data.json\n"
     ]
    }
   ],
   "source": [
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the vocab lists based on the dialogue\n",
    "\n",
    "The grammatical concepts are updated during prompt creation as it is more difficult to extract these from the dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n"
     ]
    }
   ],
   "source": [
    "for story_part in story_plan.keys():\n",
    "    dialogue = story_data_dict[story_part][\"dialogue\"]\n",
    "    vocab_used = get_vocab_from_dialogue(dialogue)\n",
    "    update_vocab_usage(vocab_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build phrases from dialogue\n",
    "\n",
    "Here we:\n",
    "1. Break up the dialogue into separate sentences. For this bit we don't care who the speaker is, we just want to create different phrases of different lengths and combinations based on the vocab int the dialogue\n",
    "2. We use another LLM call to do this, with some one-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for config.json...\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\\config.json\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Found config file at: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Successfully loaded config from: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Multiple country codes available for en: en-AU, en-GB, en-IN, en-US\n",
      "Config loader initialized.\n",
      "Config file location: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Current working directory: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\n",
      "Searching for config.json...\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\\config.json\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Found config file at: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Successfully loaded config from: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Multiple country codes available for en: en-AU, en-GB, en-IN, en-US\n",
      "Config loader initialized.\n",
      "Config file location: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Current working directory: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\n"
     ]
    }
   ],
   "source": [
    "story_data_dict = load_json(STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_part in story_data_dict:\n",
    "    dialogue = story_data_dict[story_part][\"dialogue\"]\n",
    "    story_data_dict[story_part][\"corrected_phrase_list\"] = generate_practice_phrases_from_dialogue(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/story_data.json\n"
     ]
    }
   ],
   "source": [
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate dialogue and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.09s/it]\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Required Text [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'q', 'description': 'No text queries provided.'}]}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m story_part \u001b[38;5;129;01min\u001b[39;00m tqdm(story_data_dict):\n\u001b[0;32m      6\u001b[0m     dialogue \u001b[38;5;241m=\u001b[39m story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     translated_dialogue \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_dialogue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     corrected_phrase_list \u001b[38;5;241m=\u001b[39m story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected_phrase_list\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     translated_phrase_list \u001b[38;5;241m=\u001b[39m translate_phrases(corrected_phrase_list)\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\translation.py:31\u001b[0m, in \u001b[0;36mtranslate_dialogue\u001b[1;34m(dialogue)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"translates the 'text' part of the dialogue, keeping the speaker parts\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03mthere\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m list_english_utterances \u001b[38;5;241m=\u001b[39m [utterance[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m utterance \u001b[38;5;129;01min\u001b[39;00m dialogue]\n\u001b[1;32m---> 31\u001b[0m translated_utterances \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_from_english\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_english_utterances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m translated_dialogue \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(dialogue)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dialogue_part, translation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(translated_dialogue, translated_utterances):\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\translation.py:15\u001b[0m, in \u001b[0;36mtranslate_from_english\u001b[1;34m(text, target_language)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_language \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     target_language \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTARGET_LANGUAGE\n\u001b[1;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_language\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     20\u001b[0m     result \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslatedText\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\.venv\\Lib\\site-packages\\google\\cloud\\translate_v2\\client.py:265\u001b[0m, in \u001b[0;36mClient.translate\u001b[1;34m(self, values, target_language, format_, source_language, customization_ids, model)\u001b[0m\n\u001b[0;32m    254\u001b[0m     customization_ids \u001b[38;5;241m=\u001b[39m [customization_ids]\n\u001b[0;32m    256\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target_language,\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    263\u001b[0m }\n\u001b[1;32m--> 265\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m translations \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslations\u001b[39m\u001b[38;5;124m\"\u001b[39m, ())\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(translations):\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\.venv\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 POST https://translation.googleapis.com/language/translate/v2?prettyPrint=false: Required Text [{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'q', 'description': 'No text queries provided.'}]}]"
     ]
    }
   ],
   "source": [
    "PAY_FOR_TRANSLATE_API = True\n",
    "\n",
    "if PAY_FOR_TRANSLATE_API:\n",
    "\n",
    "    for story_part in tqdm(story_data_dict):\n",
    "        dialogue = story_data_dict[story_part][\"dialogue\"]\n",
    "        translated_dialogue = translate_dialogue(dialogue)\n",
    "\n",
    "        corrected_phrase_list = story_data_dict[story_part][\"corrected_phrase_list\"]\n",
    "        translated_phrase_list = translate_phrases(corrected_phrase_list)\n",
    "\n",
    "        story_data_dict[story_part][\"translated_dialogue\"] = translated_dialogue\n",
    "        story_data_dict[story_part][\"translated_phrase_list\"] = translated_phrase_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/story_data.json\n"
     ]
    }
   ],
   "source": [
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audio Lesson\n",
    "\n",
    "The steps here are\n",
    "1. The target language dialogue at normal speed\n",
    "2. Each corrected and translated phrase in the form english - target fast - target slow\n",
    "3. Each dialogue utterance in the form english - target fast - target slow\n",
    "4. The 2 x sped up target language dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from src.audio_generation import generate_audio_from_dialogue\n",
    "test_audio = generate_audio_from_dialogue(story_data_dict[\"exposition\"][\"translated_dialogue\"][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x183289e0410>,\n",
       " <pydub.audio_segment.AudioSegment at 0x183289b62d0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n",
      "100%|██████████| 37/37 [03:55<00:00,  6.36s/it]\n",
      "100%|██████████| 7/7 [00:12<00:00,  1.80s/it]]\n",
      "100%|██████████| 34/34 [03:42<00:00,  6.55s/it]\n",
      "100%|██████████| 8/8 [00:14<00:00,  1.78s/it]]\n",
      "100%|██████████| 39/39 [04:06<00:00,  6.32s/it]\n",
      "100%|██████████| 8/8 [00:14<00:00,  1.79s/it]]\n",
      "100%|██████████| 36/36 [03:45<00:00,  6.26s/it]\n",
      "100%|██████████| 8/8 [00:13<00:00,  1.73s/it]]\n",
      "100%|██████████| 34/34 [03:26<00:00,  6.08s/it]\n",
      "100%|██████████| 5/5 [20:27<00:00, 245.56s/it]\n"
     ]
    }
   ],
   "source": [
    "PAY_FOR_TEXT_TO_SPEECH = True\n",
    "\n",
    "audio_lessons = []\n",
    "\n",
    "if PAY_FOR_TEXT_TO_SPEECH:\n",
    "    for story_part in tqdm(story_data_dict):\n",
    "\n",
    "        single_audio_lesson = []\n",
    "        single_audio_lesson_filename = story_part + \".mp3\"\n",
    "        translated_dialogue_audio_segments = generate_audio_from_dialogue(story_data_dict[story_part][\"translated_dialogue\"])\n",
    "        normal_translated_clip, fast_translated_clips = generate_normal_and_fast_audio(translated_dialogue_audio_segments)\n",
    "        single_audio_lesson.append(normal_translated_clip)\n",
    "\n",
    "        #now do phrases\n",
    "        for translated_phrase in tqdm(story_data_dict[story_part][\"translated_phrase_list\"]):\n",
    "            phrase_audio = generate_translated_phrase_audio(translated_phrase)\n",
    "            single_audio_lesson.append(phrase_audio)\n",
    "\n",
    "        #now add fast bit at the end\n",
    "        single_audio_lesson.append(fast_translated_clips)\n",
    "        single_audio_lesson = join_audio_segments(single_audio_lesson)\n",
    "        audio_lessons.append(single_audio_lesson)\n",
    "        \n",
    "        export_audio(single_audio_lesson, f\"../outputs/{single_audio_lesson_filename}\")\n",
    "    \n",
    "    full_lesson = join_audio_segments(audio_lessons, gap_ms=3000)\n",
    "    export_audio(full_lesson, filename=\"../outputs/full_lesson.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF Booklet\n",
    "So you can see the spelling of the phrases and dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Alex', 'text': 'Добро јутро, Сам! Да ли наручујете пециво?'},\n",
       " {'speaker': 'Sam', 'text': 'Да, наручујем мафин са циметом. Што то једеш?'},\n",
       " {'speaker': 'Alex',\n",
       "  'text': 'Раније сам наручио кроасан. Било је скупо, али тако добро!'},\n",
       " {'speaker': 'Sam',\n",
       "  'text': 'Свиђа ми се специјални латте овде. Да ли вам треба бадемово млеко?'},\n",
       " {'speaker': 'Alex',\n",
       "  'text': 'Не хвала. Пијем без кофеина са овсеним млеком. Није горко.'},\n",
       " {'speaker': 'Sam', 'text': 'Велики! Да ли преузимате своју наруџбу?'},\n",
       " {'speaker': 'Alex',\n",
       "  'text': 'Не, ја једем овде. Можете ли ми донети салвету, молим вас?'},\n",
       " {'speaker': 'Sam', 'text': 'Наравно! Донећу ти салвету и кашику.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_data_dict[\"exposition\"][\"translated_dialogue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_pdf_booklet(story_data_dict, output_filename=\"../outputs/story_booklet.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
