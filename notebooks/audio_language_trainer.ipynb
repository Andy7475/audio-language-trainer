{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for config.json...\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\\config.json\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Found config file at: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Successfully loaded config from: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Multiple country codes available for en: en-AU, en-GB, en-IN, en-US\n",
      "Config loader initialized.\n",
      "Config file location: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Current working directory: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\n",
      "Searching for config.json...\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\\config.json\n",
      "Checking: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Found config file at: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Successfully loaded config from: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Multiple country codes available for en: en-AU, en-GB, en-IN, en-US\n",
      "Config loader initialized.\n",
      "Config file location: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\config.json\n",
      "Current working directory: c:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\notebooks\n",
      "FFmpeg path added to system PATH: C:\\Program Files\\ffmpeg-7.0-essentials_build\\bin\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "import ipywidgets as widgets\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the parent directory of 'src' to the Python path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from src.dialogue_generation import get_vocab_from_dialogue, update_vocab_usage\n",
    "from src.dialogue_generation import generate_story_plan, generate_dialogue_prompt, generate_dialogue, generate_recap\n",
    "from src.audio_generation import  text_to_speech, play_audio, generate_audio_from_dialogue, generate_normal_and_fast_audio, generate_translated_phrase_audio, join_audio_segments, export_audio, async_process_phrases\n",
    "from src.phrase import generate_practice_phrases_from_dialogue\n",
    "from src.initialise import initialise_usage_data\n",
    "from src.utils import save_json, convert_defaultdict, save_defaultdict, load_json, create_pdf_booklet\n",
    "from src.translation import translate_dialogue, translate_phrases\n",
    "from src.audio_generation import create_m4a_with_timed_lyrics\n",
    "\n",
    "STORY_NAME = \"swedish_high_coast_2\"\n",
    "STORY_DATA_PATH = f\"../outputs/story_data_{STORY_NAME}.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Google Cloud credentials and prerequisites\n",
    "You will need a Google Project with the following APIs enabled:\n",
    "* Text to Speech\n",
    "* Translate\n",
    "* Vertex AI with the following Anthropic models enabled (from the model garden)\n",
    "    * Sonnet 3.5\n",
    "    * Haiku\n",
    "* Add your GOOGLE_PROJECT_ID to the .env file\n",
    "\n",
    "You should alter src/config.json which contains your target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "credentials, project = default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Language Trainer Workflow\n",
    "\n",
    "The aim of this project is to create audio material for you to practise a foreign language. It needs to be engaging and be tailored to words you want to practise. \n",
    "\n",
    "The overall steps we follow are:\n",
    "\n",
    "1. Create an outline story plan based on a theme you select (e.g. 'an adventure', 'a holiday in Rome'). An LLM produces a story plan following a typical story arc (exposition, rising action, climax, falling action, resolution). This ensures an engaging plot.\n",
    "2. Flesh out the story using your practice vocabulary and grammatical concepts. Vocab and concepts are sampled from lists you provide in the 'data' folder (vocab_usage.json and grammar_concepts_usage.json), with sampling being skewed towards words you haven't heard yet. The output here is a dialogue between two people (Sam and Alex).\n",
    "\n",
    "Recaps are generated between each story part so when the LLM generates the next dialogue it logically continues from the previous one.\n",
    "\n",
    "3. The dialogue is broken up into shorter practice phrases via a 'language graph' concept, so we give you not just the long-form dialogue to listen and practise to, but smaller, mixed-up phrases based on the vocab in the story, starting small and buliding to more complex phrases.\n",
    "4. Your vocab list is updated based on the produced dialogue.\n",
    "5. The smaller phrases and main dialogue are translated into your target language and convert to speech.\n",
    "6. Research shows that listening to double-speed audio (on words you already known) can help with your listening comprehension for a foreign language (it helps the brain with the ability to separate distinct words). We therefore create a fast version of the dialogue for listening practice.\n",
    "7. The audio files are stiched together to create an MP3 file for each part in the story (there are 5 parts to the story). The stages for each audio lesson are: \n",
    "* dialogue in the target language\n",
    "* practice phrases of the form 'how do you say: \"practice phrase' in 'target language'?\". A pause (where you speak in the foreign language), then the correct translation is played twice, first fast, then slow.\n",
    "* repeat of the dialogue in the target language so you can satisfy yourself you understand it properly\n",
    "* 12 repeated playings of the fast version of the dialogue to improve your listening comprehension.\n",
    "\n",
    "The intent is then you would listen to the next audio lesson in the story.\n",
    "\n",
    "\n",
    "## Setup your vocab and grammatical concepts\n",
    "You should populate or edit\n",
    "* known_vocab_list.json \n",
    "* grammar_concepts.json\n",
    "\n",
    "### Initiliase the vocab and grammar counters\n",
    "This creates vocab_usage.json (setting all values to 0) and grammar_concepts_usage.json (setting all values to 'true' and counts to 0)\n",
    "\n",
    "You can tweak these to minimise what words and concepts you are exposed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_usage_data(overwrite=False) #the overwrite commands stops you wiping all your usage data if it already exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Being Lesson Generation\n",
    "\n",
    "## Create a story plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../outputs/story_plan_swedish_high_coast_2.json\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from src.dialogue_generation import get_least_used_words, add_usage_to_words\n",
    "\n",
    "verbs_for_story = get_least_used_words(\"verbs\", 10)\n",
    "vocab_for_story = get_least_used_words(\"vocab\", 30)\n",
    "\n",
    "story_plan = generate_story_plan(story_guide = \"hiking the high coast in Sweden\", verb_list=verbs_for_story, vocab_list=vocab_for_story, test = False, story_name= STORY_NAME) #the test parameter will provide pre-canned responses avoiding LLM costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_for_story_usage = add_usage_to_words(verbs_for_story, \"verbs\")\n",
    "vocab_for_story_usage = add_usage_to_words(vocab_for_story, \"vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all dialogue\n",
    "\n",
    "1. Create dialouge LLM prompt based on the story part\n",
    "2. LLM generates dialogue\n",
    "3. LLM generates recap\n",
    "4. move to next story part and repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n",
      "Data saved to ../data/vocab_usage.json\n"
     ]
    }
   ],
   "source": [
    "PAY_FOR_LLM = True\n",
    "\n",
    "if PAY_FOR_LLM:\n",
    "    story_data_dict = defaultdict(lambda: defaultdict(str))\n",
    "    recap = \"This is the beginning of the story.\"\n",
    "    for step, story_part in enumerate(list(story_plan.keys())):\n",
    "        prompt = generate_dialogue_prompt(story_part=story_part,\n",
    "                                        story_part_outline=story_plan[story_part],\n",
    "                                        last_recap = recap,\n",
    "                                        verb_usage_str=verbs_for_story_usage,\n",
    "                                        vocab_usage_str=vocab_for_story_usage,\n",
    "                                        verb_use_count=5,\n",
    "                                        vocab_use_count=10,\n",
    "                                        grammar_concept_count=5,\n",
    "                                        grammar_use_count=3)\n",
    "        dialogue = generate_dialogue(prompt)\n",
    "        vocab_used = get_vocab_from_dialogue(dialogue)\n",
    "        update_vocab_usage(vocab_used)\n",
    "        verbs_for_story_usage = add_usage_to_words(verbs_for_story, \"verbs\")\n",
    "        vocab_for_story_usage = add_usage_to_words(vocab_for_story, \"vocab\")\n",
    "        recap = generate_recap(dialogue, test=False)\n",
    "        story_data_dict[story_part][\"dialogue_generation_prompt\"] = prompt\n",
    "        story_data_dict[story_part][\"dialogue\"] = dialogue\n",
    "        story_data_dict[story_part][\"recap\"] = recap\n",
    "\n",
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build phrases from dialogue\n",
    "\n",
    "Here we:\n",
    "1. Break up the dialogue into separate sentences. For this bit we don't care who the speaker is, we just want to create different phrases of different lengths and combinations based on the vocab int the dialogue\n",
    "2. We use another LLM call to do this, with some one-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_data_dict = load_json(STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_part in story_data_dict:\n",
    "    dialogue = story_data_dict[story_part][\"dialogue\"]\n",
    "    story_data_dict[story_part][\"corrected_phrase_list\"] = generate_practice_phrases_from_dialogue(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../outputs/story_data_swedish_high_coast.json\n"
     ]
    }
   ],
   "source": [
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate dialogue and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "PAY_FOR_TRANSLATE_API = True\n",
    "\n",
    "if PAY_FOR_TRANSLATE_API:\n",
    "\n",
    "    for story_part in tqdm(story_data_dict):\n",
    "        dialogue = story_data_dict[story_part][\"dialogue\"]\n",
    "        translated_dialogue = translate_dialogue(dialogue)\n",
    "\n",
    "        corrected_phrase_list = story_data_dict[story_part][\"corrected_phrase_list\"]\n",
    "        translated_phrase_list = translate_phrases(corrected_phrase_list)\n",
    "\n",
    "        story_data_dict[story_part][\"translated_dialogue\"] = translated_dialogue\n",
    "        story_data_dict[story_part][\"translated_phrase_list\"] = translated_phrase_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../outputs/story_data_swedish_high_coast.json\n"
     ]
    }
   ],
   "source": [
    "save_defaultdict(story_data_dict, STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audio Lesson\n",
    "\n",
    "The steps here are\n",
    "1. The target language dialogue at normal speed\n",
    "2. Each corrected and translated phrase in the form english - target fast - target slow\n",
    "3. Each dialogue utterance in the form english - target fast - target slow\n",
    "4. The 2 x sped up target language dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    }
   ],
   "source": [
    "# attach audio segment data to story_data.json for later incorporation into M4A file\n",
    "%autoreload 2\n",
    "from src.audio_generation import async_process_phrases, generate_audio_from_dialogue, async_process_phrases_v2\n",
    "%autoawait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_data_dict =load_json(STORY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object AsyncFuture.result at 0x000001DF906B42B0>\n",
      "Waiting for Jag måste avsluta...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'done'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m translated_phrases \u001b[38;5;241m=\u001b[39m story_data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolution\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_phrase_list\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m tranlsated_phrases_audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_process_phrases_v2(translated_phrases)\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\audio_generation.py:572\u001b[0m, in \u001b[0;36masync_process_phrases_v2\u001b[1;34m(phrases, max_concurrency)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m async_generate_translated_phrase_audio_v2(phrase)\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[limited_task(phrase) \u001b[38;5;28;01mfor\u001b[39;00m phrase \u001b[38;5;129;01min\u001b[39;00m phrases])\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\audio_generation.py:570\u001b[0m, in \u001b[0;36masync_process_phrases_v2.<locals>.limited_task\u001b[1;34m(phrase)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlimited_task\u001b[39m(phrase):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m--> 570\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m async_generate_translated_phrase_audio_v2(phrase)\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\audio_generation.py:562\u001b[0m, in \u001b[0;36masync_generate_translated_phrase_audio_v2\u001b[1;34m(translated_phrase, english_voice_models, target_voice_models)\u001b[0m\n\u001b[0;32m    539\u001b[0m     target_voice_models \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtarget_language_voice_models\n\u001b[0;32m    541\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    542\u001b[0m     async_text_to_speech_v2(\n\u001b[0;32m    543\u001b[0m         translated_phrase[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m     ),\n\u001b[0;32m    560\u001b[0m ]\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\audio_generation.py:494\u001b[0m, in \u001b[0;36masync_text_to_speech_v2\u001b[1;34m(text, language_code, voice_name, speaking_rate)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Wait for the operation to complete\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m():\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStill waiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'done'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object AsyncFuture.result at 0x000001DFFA5FE330>\n",
      "Waiting for I must finish...\n",
      "<coroutine object AsyncFuture.result at 0x000001DFFA5FDF20>\n",
      "Waiting for It's beautiful...\n",
      "<coroutine object AsyncFuture.result at 0x000001DF906B4AD0>\n",
      "Waiting for Det är vackert...\n",
      "<coroutine object AsyncFuture.result at 0x000001DF90287510>\n",
      "Waiting for Du undervisar...\n",
      "<coroutine object AsyncFuture.result at 0x000001DF906B41E0>\n",
      "Waiting for Det är vackert...\n",
      "<coroutine object AsyncFuture.result at 0x000001DF903CF780>\n",
      "Waiting for Jag måste avsluta...\n",
      "<coroutine object AsyncFuture.result at 0x000001DFFA79E740>\n",
      "Waiting for Du undervisar...\n",
      "<coroutine object AsyncFuture.result at 0x000001DF903CF780>\n",
      "Waiting for You're teaching...\n"
     ]
    }
   ],
   "source": [
    "translated_phrases = story_data_dict[\"resolution\"][\"translated_phrase_list\"][0:3]\n",
    "tranlsated_phrases_audio = await async_process_phrases_v2(translated_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_phrases = story_data_dict[\"resolution\"][\"translated_phrase_list\"]\n",
    "tranlsated_phrases_audio = await async_process_phrases(translated_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposition dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [04:37<18:29, 277.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposition phrases done\n",
      "rising_action dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [09:18<13:58, 279.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rising_action phrases done\n",
      "climax dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [14:08<09:28, 284.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climax phrases done\n",
      "falling_action dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [18:59<04:46, 286.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling_action phrases done\n",
      "resolution dialogue done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [23:26<00:00, 281.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution phrases done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type AudioSegment is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         story_data_dict[story_part][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslated_phrase_list_audio\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tranlsated_phrases_audio\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstory_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m phrases done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43msave_defaultdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstory_data_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTORY_DATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\utils.py:31\u001b[0m, in \u001b[0;36msave_defaultdict\u001b[1;34m(d, filepath)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_defaultdict\u001b[39m(d, filepath):\n\u001b[0;32m     30\u001b[0m     normal_dict \u001b[38;5;241m=\u001b[39m convert_defaultdict(d)\n\u001b[1;32m---> 31\u001b[0m     \u001b[43msave_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\i5\\Documents\\Python Scripts\\audio-language-trainer\\src\\utils.py:41\u001b[0m, in \u001b[0;36msave_json\u001b[1;34m(data, file_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_json\u001b[39m(data, file_path):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 41\u001b[0m         \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\i5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type AudioSegment is not JSON serializable"
     ]
    }
   ],
   "source": [
    "\n",
    "PAY_FOR_TEXT_TO_SPEECH = True\n",
    "\n",
    "story_data_dict =load_json(STORY_DATA_PATH)\n",
    "if PAY_FOR_TEXT_TO_SPEECH:\n",
    "    for story_part in tqdm(story_data_dict):\n",
    "\n",
    "        translated_dialogue_audio_segments = generate_audio_from_dialogue(story_data_dict[story_part][\"translated_dialogue\"])\n",
    "        story_data_dict[story_part][\"translated_dialogue_audio\"] = translated_dialogue_audio_segments\n",
    "        normal_translated_clip, fast_translated_clips = generate_normal_and_fast_audio(translated_dialogue_audio_segments)\n",
    "        story_data_dict[story_part][\"translated_dialogue_audio_fast\"] = fast_translated_clips\n",
    "        print(f\"{story_part} dialogue done\")\n",
    "        #now do phrases asynchronoulsy (still unsure if Google API allows this, not getting huge speed up)\n",
    "        translated_phrases = story_data_dict[story_part][\"translated_phrase_list\"]\n",
    "        tranlsated_phrases_audio = await async_process_phrases(translated_phrases)\n",
    "        story_data_dict[story_part][\"translated_phrase_list_audio\"] = tranlsated_phrases_audio\n",
    "        print(f\"{story_part} phrases done\")\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the dictionary to a file\n",
    "with open(F'{STORY_DATA_PATH}.pkl', 'wb') as file:\n",
    "    pickle.dump(story_data_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate M4A file with synchronised captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from src.config_loader import config\n",
    "#get lists and audio clips synced together\n",
    "full_audio_list = []\n",
    "full_captions_list = []\n",
    "\n",
    "\n",
    "#fast dialogue (no text)\n",
    "PAUSE_TEXT = \"---------\"\n",
    "THINKING_GAP = AudioSegment.silent(duration=config.THINKING_GAP_MS)\n",
    "GAP_BETWEEN_PHRASES = AudioSegment.silent(duration=500)\n",
    "#translated dialogue\n",
    "\n",
    "for story_part in story_data_dict:\n",
    "\n",
    "    audio_list = []\n",
    "    captions_list = []\n",
    "    dialogue_list = [utterence[\"text\"] for utterence in story_data_dict[story_part][\"translated_dialogue\"]]\n",
    "    dialogue_audio_list = story_data_dict[story_part][\"translated_dialogue_audio\"]\n",
    "\n",
    "    audio_list.append(GAP_BETWEEN_PHRASES)\n",
    "    captions_list.append(f\"{story_part} - First dialogue\")\n",
    "\n",
    "    audio_list.extend(dialogue_audio_list)\n",
    "    captions_list.extend(dialogue_list)\n",
    "    #print(f\"audio {len(audio_list)} - captions {len(captions_list)}\")\n",
    "\n",
    "    audio_list.append(GAP_BETWEEN_PHRASES)\n",
    "    captions_list.append(f\"{story_part} - Practice phrases\")\n",
    "    \n",
    "    for step, phrase in enumerate(story_data_dict[story_part][\"translated_phrase_list\"]):\n",
    "        english_text = phrase[0]\n",
    "        target_text = phrase[1]\n",
    "\n",
    "        english_audio = story_data_dict[story_part][\"translated_phrase_list_audio\"][step][0]\n",
    "        target_audio_slow = story_data_dict[story_part][\"translated_phrase_list_audio\"][step][1]\n",
    "        target_audio_normal = story_data_dict[story_part][\"translated_phrase_list_audio\"][step][2]\n",
    "\n",
    "        audio_list.append(english_audio)\n",
    "        captions_list.append(english_text)\n",
    "\n",
    "        audio_list.append(THINKING_GAP)\n",
    "        captions_list.append(PAUSE_TEXT)\n",
    "\n",
    "        audio_list.append(target_audio_normal)\n",
    "        captions_list.append(target_text)\n",
    "\n",
    "        audio_list.append(GAP_BETWEEN_PHRASES)\n",
    "        captions_list.append(PAUSE_TEXT)\n",
    "\n",
    "        audio_list.append(target_audio_slow)\n",
    "        captions_list.append(target_text)\n",
    "\n",
    "        audio_list.append(GAP_BETWEEN_PHRASES)\n",
    "        captions_list.append(PAUSE_TEXT)\n",
    "\n",
    "    audio_list.append(story_data_dict[story_part][\"translated_dialogue_audio_fast\"])\n",
    "    captions_list.append(f\"{story_part} - Repeated Fast Dialogue\")\n",
    "\n",
    "    audio_list.append(GAP_BETWEEN_PHRASES)\n",
    "    captions_list.append(f\"{story_part} - Final Dialogue\")\n",
    "    \n",
    "    audio_list.extend(dialogue_audio_list)\n",
    "    captions_list.extend(dialogue_list)\n",
    "\n",
    "    create_m4a_with_timed_lyrics(audio_list, captions_list, F\"{STORY_NAME}_{story_part}.m4a\")\n",
    "    full_audio_list.extend(audio_list)\n",
    "    full_captions_list.extend(captions_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the complete story as a single dialogue at the end\n",
    "\n",
    "all_dialogue_audio = []\n",
    "all_dialogue_captions = []\n",
    "\n",
    "for story_part in story_data_dict:\n",
    "    dialogue_list = [utterence[\"text\"] for utterence in story_data_dict[story_part][\"translated_dialogue\"]]\n",
    "    dialogue_audio_list = story_data_dict[story_part][\"translated_dialogue_audio\"]\n",
    "    all_dialogue_audio.extend(dialogue_audio_list)\n",
    "    all_dialogue_captions.extend(dialogue_list)\n",
    "\n",
    "    all_dialogue_audio.append(GAP_BETWEEN_PHRASES)\n",
    "    all_dialogue_captions.append(PAUSE_TEXT)\n",
    "\n",
    "full_audio_list.extend(all_dialogue_audio)\n",
    "full_captions_list.extend(all_dialogue_captions)\n",
    "\n",
    "\n",
    "create_m4a_with_timed_lyrics(full_audio_list, full_captions_list, F\"final_lesson_{STORY_NAME}.m4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF Booklet\n",
    "So you can see the spelling of the phrases and dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdf_booklet(story_data_dict, output_filename=f\"../outputs/story_booklet_{STORY_NAME}.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
